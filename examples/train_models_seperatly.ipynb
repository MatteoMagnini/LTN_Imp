{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-07T12:36:06.981575Z",
     "start_time": "2024-08-07T12:36:06.225532Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Â Data Processing\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from examples.generator import generate_balanced_dataset, draw_circles, draw_rectangles\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce271d4",
   "metadata": {},
   "source": [
    "## Data Processing and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "967fcf7f9752f670",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-07T12:36:07.497689Z",
     "start_time": "2024-08-07T12:36:06.982564Z"
    }
   },
   "outputs": [],
   "source": [
    "data, metadata = generate_balanced_dataset(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9a55208b6363223",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-07T12:36:07.500257Z",
     "start_time": "2024-08-07T12:36:07.498415Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eee268618c7c6ecc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-07T12:36:07.502965Z",
     "start_time": "2024-08-07T12:36:07.500913Z"
    }
   },
   "outputs": [],
   "source": [
    "metadata = pd.DataFrame(metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59cd3fd112be9b64",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-07T12:36:07.613914Z",
     "start_time": "2024-08-07T12:36:07.511710Z"
    }
   },
   "outputs": [],
   "source": [
    "image_paths = [item for item in data[0]]\n",
    "images = []\n",
    "\n",
    "for path in image_paths:\n",
    "    try:\n",
    "        img = Image.open(path).convert('RGB')  # Convert to RGB to ensure consistency\n",
    "        img = np.array(img)\n",
    "        img_tensor = torch.tensor(img, dtype=torch.float32)  # Convert to PyTorch tensor\n",
    "        images.append(img_tensor)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading image {path}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "615ce622",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mv/_dg3pqgn2zdf7f95_1dg07rw0000gn/T/ipykernel_65540/1755259665.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.images = torch.stack([torch.tensor(image).permute(2, 0, 1) for image in images])\n"
     ]
    }
   ],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, images, metadata):\n",
    "        self.images = torch.stack([torch.tensor(image).permute(2, 0, 1) for image in images])\n",
    "        self.metadata = torch.tensor(metadata).float()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        metadata = self.metadata[idx]\n",
    "        return image, metadata\n",
    "    \n",
    "batch_size = 25\n",
    "\n",
    "circle_metadata = metadata[[\"circle_center_x\",\"circle_center_y\", \"circle_radius\"]]\n",
    "\n",
    "rectangle_metadata = metadata[[\"rect_tl_x\",\t\"rect_tl_y\"\t,\"rect_br_x\"\t,\"rect_br_y\"]]\n",
    "\n",
    "train_images, test_images, train_circle_labels, test_circle_labels = train_test_split( images, circle_metadata.values, test_size=0.2, random_state=42)\n",
    "\n",
    "train_images, test_images, train_rect_labels, test_rect_labels = train_test_split(images, rectangle_metadata.values, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create the training and test datasets for circles\n",
    "train_circle_dataset = ImageDataset(train_images, train_circle_labels)\n",
    "test_circle_dataset = ImageDataset(test_images, test_circle_labels)\n",
    "\n",
    "# Create the training and test datasets for rectangles\n",
    "train_rect_dataset = ImageDataset(train_images, train_rect_labels)\n",
    "test_rect_dataset = ImageDataset(test_images, test_rect_labels)\n",
    "\n",
    "# Create the dataloaders\n",
    "batch_size = 25\n",
    "\n",
    "# Circle dataloaders\n",
    "train_circle_dataloader = DataLoader(train_circle_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_circle_dataloader = DataLoader(test_circle_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Rectangle dataloaders\n",
    "train_rect_dataloader = DataLoader(train_rect_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_rect_dataloader = DataLoader(test_rect_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "debee8d5",
   "metadata": {},
   "source": [
    "# Models and Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a4374e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CircleDetector(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CircleDetector, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "        self.fc1 = nn.Linear(in_features=64*16*16, out_features=128)\n",
    "        self.bn_fc1 = nn.BatchNorm1d(128)\n",
    "        self.fc2 = nn.Linear(in_features=128, out_features=3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.bn1(self.conv1(x)))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.leaky_relu(self.bn2(self.conv2(x)))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.leaky_relu(self.bn3(self.conv3(x)))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.leaky_relu(self.bn_fc1(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        c_x, c_y, r = torch.tanh(x[:, 0]), torch.tanh(x[:, 1]), torch.sigmoid(x[:, 2])\n",
    "        return c_x, c_y, r\n",
    "    \n",
    "class RectangleDetector(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RectangleDetector, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "        self.fc1 = nn.Linear(in_features=64*16*16, out_features=128)\n",
    "        self.bn_fc1 = nn.BatchNorm1d(128)\n",
    "        self.fc2 = nn.Linear(in_features=128, out_features=4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.bn1(self.conv1(x)))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.leaky_relu(self.bn2(self.conv2(x)))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.leaky_relu(self.bn3(self.conv3(x)))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.leaky_relu(self.bn_fc1(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        t_x, t_y,b_x, b_y = torch.tanh(x[:, 0]), torch.tanh(x[:, 1]), torch.tanh(x[:, 2]), torch.tanh(x[:, 3])\n",
    "        return t_x, t_y, b_x, b_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "365387f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_circle(model, dataloader, criterion, optimizer, num_epochs=25, device='cpu'):\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            c_x, c_y, r = model(inputs)\n",
    "            outputs = torch.stack((c_x, c_y, r), dim=1)\n",
    "            \n",
    "            # Calculate loss\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Backward pass and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "        epoch_loss = running_loss / len(dataloader.dataset)\n",
    "        print(f'Epoch {epoch}/{num_epochs - 1}, Loss: {epoch_loss:.4f}')\n",
    "\n",
    "def train_rect(model, dataloader, criterion, optimizer, num_epochs=25, device='cpu'):\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            tl_x, tl_y, br_x, br_y = model(inputs)\n",
    "            outputs = torch.stack((tl_x, tl_y, br_x, br_y), dim=1)\n",
    "            \n",
    "            # Calculate loss\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Backward pass and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "        epoch_loss = running_loss / len(dataloader.dataset)\n",
    "        print(f'Epoch {epoch}/{num_epochs - 1}, Loss: {epoch_loss:.4f}')\n",
    "\n",
    "\n",
    "def evaluate_model_circle(model, dataloader, device='cpu'):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            c_x, c_y, r = model(inputs)\n",
    "            preds = torch.stack((c_x, c_y, r), dim=1)\n",
    "\n",
    "            all_preds.append(preds.cpu().numpy())\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "\n",
    "    all_preds = np.concatenate(all_preds, axis=0)\n",
    "    all_labels = np.concatenate(all_labels, axis=0)\n",
    "\n",
    "    mae = mean_absolute_error(all_labels, all_preds)\n",
    "    print(f'Mean Absolute Error: {mae:.4f}')\n",
    "    return mae\n",
    "\n",
    "\n",
    "def evaluate_model_rect(model, dataloader, device='cpu'):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            tl_x, tl_y, br_x, br_y = model(inputs)\n",
    "            preds = torch.stack((tl_x, tl_y, br_x, br_y), dim=1)\n",
    "\n",
    "            all_preds.append(preds.cpu().numpy())\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "\n",
    "    all_preds = np.concatenate(all_preds, axis=0)\n",
    "    all_labels = np.concatenate(all_labels, axis=0)\n",
    "\n",
    "    mae = mean_absolute_error(all_labels, all_preds)\n",
    "    print(f'Mean Absolute Error: {mae:.4f}')\n",
    "    return mae\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2bda82",
   "metadata": {},
   "source": [
    "# Circle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0220da3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.9793\n",
      "\n",
      "Epoch 0/9, Loss: 0.3352\n",
      "Epoch 1/9, Loss: 0.1172\n",
      "Epoch 2/9, Loss: 0.0476\n",
      "Epoch 3/9, Loss: 0.0237\n",
      "Epoch 4/9, Loss: 0.0130\n",
      "Epoch 5/9, Loss: 0.0097\n",
      "Epoch 6/9, Loss: 0.0067\n",
      "Epoch 7/9, Loss: 0.0047\n",
      "Epoch 8/9, Loss: 0.0049\n",
      "Epoch 9/9, Loss: 0.0037\n",
      "\n",
      "Mean Absolute Error: 0.0544\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float32(0.054447632)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "circle = CircleDetector()\n",
    "evaluate_model_circle(circle, train_circle_dataloader, device='cpu')\n",
    "print()\n",
    "train_circle(circle, train_circle_dataloader, nn.MSELoss(), torch.optim.Adam(circle.parameters()), num_epochs=10, device='cpu')\n",
    "print()\n",
    "evaluate_model_circle(circle, test_circle_dataloader, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5492dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data, test_metadata = next(iter(test_circle_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cda3d388",
   "metadata": {},
   "outputs": [],
   "source": [
    "circle.eval()\n",
    "instance = test_data[1].unsqueeze(0)\n",
    "c_x, c_y, r = circle(instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "481ea89e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAIAAABMXPacAAADpUlEQVR4Ae2b23KbQBAFo1T+O/KXE3RbZmFBqyTQg6vzYoSGPdDNoaiycxmG4Yf/OAI/uWiTbwQUAN8HClAATACOtwEKgAnA8TZAATABON4GKAAmAMfbAAXABOB4G6AAmAAcbwMUABOA422AAmACcLwNUABMAI63AQqACcDxNkABMAE43gYoACYAx9sABcAE4HgboACYABxvAxQAE4DjbYACYAJwvA1QAEwAjrcBCoAJwPE2QAEwATjeBigAJgDH2wAFwATgeBugAJgAHG8DFAATgONtgAJgAnC8DVAATACOtwEKgAnA8TZAATABON4GKAAmAMfbAAXABOB4G6AAmAAcbwMUABOA422AAmACcLwNUABMAI63AQqACcDxNkABMAE43gYoACYAx9sABcAE4HgboACYABxvAxQAE4DjbYACYAJwvA1QAEwAjrcBCoAJwPE2ABbwC87/h/jL16V59PB7aO7PufMyDGc63RHiGvcl31OYOJOAfvRRRnINuQVcpofM5Rqp3rbXyC49rU3OVyQ+pxQQuD+YzOgP1/vuzYfnTENaB/kEbNJ/oi+36qaDcSpqyOkg2WvojP4wxHv/RnBGfDZfxLw2IvQo4/U9/zNTAyLNO+iILKK8YVsMb7DcWmfjsEO+StOABdA31GIV4rEtalFeXLY1e/S+HAIiwUj2TiPiq/DEybhCNfT8sLpIa/jIfQkERHYvpr336Wv+hiyus4mwd/HNRf7XlwkElEuJNF8739+5raNeR1c/3y9VjR/0IZOAgy45VwwtoDw3wo1cHhG992w5tqy2ArksWCJWBo/bTQs47kqTJikAFqMABcAE4HgboACYABxPN6D7DXKLU3n7LKttTef6jhbQorHf23p5/S8RrfxD92USUG7kjwj83VEfRew5nEBAfG4saJZ7tg0hzsd1WtNvlmodcsC+BALGq4zs7ky7HhGf0I8ouxaPB+y5nUNAy0G56vad+yH99iIlg9vI9CvJkULEOn66TmCm27aeqdozjVdbkf60TjWCfUgmYORQ860cXBeY4rNr8eVjR2b64xmmeQQVfDXT+HcoUcZtvJ4sC8SN5PTHU83XgIrf8y/jZuh7HiMR/bhkzyEx+bDt3AIChhnQDab9k2F5bPM0AkZCS7I92NLe+4+TP5OA5xl/TX+xuy0gOfqzCijQ1wpxCu7TVZzuP2iUU/8eG/leQ78H1+6rUEA3qn0GFbAP1+5VFdCNap9BBezDtXvVPyKZ08ERzHl1AAAAAElFTkSuQmCC",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=128x128>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "draw_circles(*test_metadata[1], c_x, c_y, r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd3fadb",
   "metadata": {},
   "source": [
    "# Rectangle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a6145dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.9521\n",
      "\n",
      "Epoch 0/9, Loss: 0.2560\n",
      "Epoch 1/9, Loss: 0.0624\n",
      "Epoch 2/9, Loss: 0.0246\n",
      "Epoch 3/9, Loss: 0.0143\n",
      "Epoch 4/9, Loss: 0.0092\n",
      "Epoch 5/9, Loss: 0.0080\n",
      "Epoch 6/9, Loss: 0.0078\n",
      "Epoch 7/9, Loss: 0.0067\n",
      "Epoch 8/9, Loss: 0.0045\n",
      "Epoch 9/9, Loss: 0.0040\n",
      "\n",
      "Mean Absolute Error: 0.0423\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float32(0.04227316)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rect = RectangleDetector()\n",
    "evaluate_model_rect(rect, train_rect_dataloader, device='cpu')\n",
    "print()\n",
    "train_rect(rect, train_rect_dataloader, nn.MSELoss(), torch.optim.Adam(rect.parameters()), num_epochs=10, device='cpu')\n",
    "print()\n",
    "evaluate_model_rect(rect, test_rect_dataloader, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "037b99c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data, test_metadata = next(iter(test_rect_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "51214285",
   "metadata": {},
   "outputs": [],
   "source": [
    "rect.eval()\n",
    "instance = test_data[2].unsqueeze(0)\n",
    "t_x, t_y, b_x, b_y = rect(instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ec28439d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAIAAABMXPacAAACYklEQVR4Ae3a0UojURBFUTPMf4tf3jIIonkIoazrhmH5lKRTddq9c+5T367revHXEfjTRUv+R4CA+HdAAAExgTheAwiICcTxGkBATCCO1wACYgJxvAYQEBOI4zWAgJhAHK8BBMQE4ngNICAmEMdrAAExgTheAwiICcTxGkBATCCO1wACYgJxvAYQEBOI4zWAgJhAHK8BBMQE4ngNICAmEMdrAAExgTheAwiICcTxGkBATCCO1wACYgJxvAYQEBOI4zWAgJhAHK8BBMQE4ngNICAmEMdrAAExgTheAwiICcTxGkBATCCO1wACYgJxvAYQEBOI4zWAgJhAHK8BBMQE4ngNICAmEMdrAAExgTheAwiICcTxGkBATCCO1wACYgJxvAYQEBOI4zWAgJhAHK8BBMQE4ngNICAmEMdrAAExgTheAwiICcTxGkBATCCO1wACYgJx/N8T+W+3txNrn9/5er0+/+X2m46glv8LAbGAI0fQ5//0cRTcbp8fLL+4rm8L86Pv29089+asgLt7uON1d/X5t+eMPn8PW990BG2RHO4hYAhua4yALZLDPQQMwW2NEbBFcriHgCG4rTECtkgO9xAwBLc1RsAWyeEeAobgtsYI2CI53EPAENzWGAFbJId7CBiC2xojYIvkcA8BQ3BbYwRskRzuIWAIbmuMgC2Swz0EDMFtjRGwRXK4h4AhuK0xArZIDvcQMAS3NUbAFsnhntu19bjalxvIHxH0dPQXG14+JOAIeojn/MUjR9DdbZ97lvbA8Xl378ffasBxxI8DfuPx9P/gd/oY4k+uasBP6C3MvgNdTBr7TguPSwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=128x128>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "draw_rectangles(*test_metadata[2], t_x, t_y, b_x, b_y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
