{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Processing\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from examples.generator import generate_dataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Torch \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "# LTN\n",
    "from nltk.sem.logic import Expression\n",
    "from ltn_imp.automation.knowledge_base import KnowledgeBase\n",
    "from ltn_imp.automation.data_loaders import LoaderWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Expression.fromstring(\"t11\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(generate_dataset(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = [item for item in data[0]]\n",
    "images = []\n",
    "for path in image_paths:\n",
    "    try:\n",
    "        img = Image.open(path).convert('RGB')  # Convert to RGB to ensure consistency\n",
    "        img = np.array(img)\n",
    "        img_tensor = torch.tensor(img, dtype=torch.float32)  # Convert to PyTorch tensor\n",
    "        images.append(img_tensor)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading image {path}: {e}\")\n",
    "        \n",
    "labels = torch.tensor(data[1], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, images, labels):\n",
    "        # Convert the list of images to a tensor and permute dimensions to [batch_size, channels, height, width]\n",
    "        self.images = torch.stack([torch.tensor(image).permute(2, 0, 1) for image in images])\n",
    "        self.labels = torch.tensor(labels).float()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        return image, label\n",
    "    \n",
    "batch_size = 25\n",
    "\n",
    "# Split the data into training and test sets\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(images,labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create the training dataset\n",
    "train_dataset = ImageDataset(train_data, train_labels)\n",
    "\n",
    "# Create the test dataset\n",
    "test_dataset = ImageDataset(test_data, test_labels)\n",
    "\n",
    "# Create the training dataloader\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Create the test dataloader\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of training images: {len(train_data)}\")\n",
    "print(f\"Number of training labels: {len(train_labels)}\")\n",
    "print(f\"Number of test images: {len(test_data)}\")\n",
    "print(f\"Number of test labels: {len(test_labels)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(train_data[0].numpy().astype(np.uint8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CircleDetector(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CircleDetector, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.fc1 = nn.Linear(in_features=64*16*16, out_features=128)  # Adjusted in_features to 16384\n",
    "        self.fc2 = nn.Linear(in_features=128, out_features=3)  \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        c_x, c_y, r = x[:,0], x[:,1], x[:,2]\n",
    "        return c_x, c_y, r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RectangleDetector(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RectangleDetector, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.fc1 = nn.Linear(in_features=64*16*16, out_features=128)  # Adjusted in_features to 16384\n",
    "        self.fc2 = nn.Linear(in_features=128, out_features=4)  \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        t_x, t_y,b_x, b_y = x[:,0], x[:,1], x[:,2], x[:,3]\n",
    "        return t_x, t_y, b_x, b_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class BoundingBox(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BoundingBox, self).__init__()\n",
    "\n",
    "    def forward(self, c1, c2, r, t21=None, t22=None, b21=None, b22=None):\n",
    "        if t21 is None and t22 is None and b21 is None and b22 is None:\n",
    "            t21 = c1 - r\n",
    "            t22 = c2 - r\n",
    "            b21 = c1 + r\n",
    "            b22 = c2 + r\n",
    "            return t21, t22, b21, b22\n",
    "        else:\n",
    "            t21_check = 1 - torch.tanh(torch.abs(t21 - (c1 - r)))**2\n",
    "            t22_check = 1 - torch.tanh(torch.abs(t22 - (c2 - r)))**2\n",
    "            b21_check = 1 - torch.tanh(torch.abs(b21 - (c1 + r)))**2\n",
    "            b22_check = 1 - torch.tanh(torch.abs(b22 - (c2 + r)))**2\n",
    "            return t21_check * t22_check * b21_check * b22_check\n",
    "\n",
    "    def __call__(self, *args):\n",
    "        return self.forward(*args)\n",
    "\n",
    "class Inside(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Inside, self).__init__()\n",
    "\n",
    "    def forward(self, t11, t12, b11, b12, t21, t22, b21, b22):\n",
    "        smooth_lt_t11_t21 = torch.sigmoid(10 * (t21 - t11))\n",
    "        smooth_lt_t12_t22 = torch.sigmoid(10 * (t22 - t12))\n",
    "        smooth_lt_b11_b21 = torch.sigmoid(10 * (b21 - b11))\n",
    "        smooth_lt_b12_b22 = torch.sigmoid(10 * (b22 - b12))\n",
    "        return smooth_lt_t11_t21 * smooth_lt_t12_t22 * smooth_lt_b11_b21 * smooth_lt_b12_b22\n",
    "\n",
    "    def __call__(self, *args):\n",
    "        return self.forward(*args)\n",
    "\n",
    "class Outside(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Outside, self).__init__()\n",
    "\n",
    "    def forward(self, t11, t12, b11, b12, t21, t22, b21, b22):\n",
    "        smooth_gt_t11_t21 = torch.sigmoid(10 * (t11 - t21))\n",
    "        smooth_gt_t12_t22 = torch.sigmoid(10 * (t12 - t22))\n",
    "        smooth_gt_b11_b21 = torch.sigmoid(10 * (b11 - b21))\n",
    "        smooth_gt_b12_b22 = torch.sigmoid(10 * (b12 - b22))\n",
    "        return smooth_gt_t11_t21 * smooth_gt_t12_t22 * smooth_gt_b11_b21 * smooth_gt_b12_b22\n",
    "\n",
    "    def __call__(self, *args):\n",
    "        return self.forward(*args)\n",
    "\n",
    "class Intersect(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Intersect, self).__init__()\n",
    "\n",
    "    def forward(self, t11, t12, b11, b12, t21, t22, b21, b22):\n",
    "        smooth_lt_t11_t21 = torch.sigmoid(10 * (t21 - t11))\n",
    "        smooth_lt_t12_t22 = torch.sigmoid(10 * (t22 - t12))\n",
    "        smooth_lt_b11_b21 = torch.sigmoid(10 * (b21 - b11))\n",
    "        smooth_lt_b12_b22 = torch.sigmoid(10 * (b22 - b12))\n",
    "        smooth_gt_t11_t21 = torch.sigmoid(10 * (t11 - t21))\n",
    "        smooth_gt_t12_t22 = torch.sigmoid(10 * (t12 - t22))\n",
    "        smooth_gt_b11_b21 = torch.sigmoid(10 * (b11 - b21))\n",
    "        smooth_gt_b12_b22 = torch.sigmoid(10 * (b12 - b22))\n",
    "        inside = smooth_lt_t11_t21 * smooth_lt_t12_t22 * smooth_lt_b11_b21 * smooth_lt_b12_b22\n",
    "        outside = smooth_gt_t11_t21 * smooth_gt_t12_t22 * smooth_gt_b11_b21 * smooth_gt_b12_b22\n",
    "        return 1 - (inside + outside - inside * outside)  # Smooth approximation of NOT OR (XOR)\n",
    "\n",
    "    def __call__(self, *args):\n",
    "        return self.forward(*args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ancillary_rules = [\n",
    "#     \"forall c1 c2 r t21 t22 b21 b22. box(c1, c2, r, t21, t22, b21, b22) <-> (t21 = c1 - r and t22 = c2 - r and b21 = c1 + r and b22 = c2 + r)\",\n",
    "#     \"forall t11 t12 b11 b12 t21 t22 b21 b22. in(t11, t12, b11, b12, t21, t22, b21, b22) <-> (t11 >= t21 and t12 >= t22 and b11 <= b21 and b12 <= b22)\",\n",
    "#     \"forall t11 t12 b11 b12 t21 t22 b21 b22. out(t11, t12, b11, b12, t21, t22, b21, b22) <-> (t11 > b21 or t12 > b22 or b11 < t21 or b12 < t22)\",\n",
    "#     \"forall t11 t12 b11 b12 t21 t22 b21 b22. int(t11, t12, b11, b12, t21, t22, b21, b22) <-> (not out(t11, t12, b11, b12, t21, t22, b21, b22) and not in(t11, t12, b11, b12, t21, t22, b21, b22))\"\n",
    "# ]\n",
    "\n",
    "learning_rules = [\n",
    "    \"all i. ((y = in) -> (Circle(i, c1, c2, r) and Rect(i, t11, t12, b11, b12) and box(c1, c2, r, t21, t22, b21, b22) and in(t11, t12, b11, b12, t21, t22, b21, b22)))\",\n",
    "    \"all i. ((y = int) -> (Circle(i, c1, c2, r) and Rect(i, t11, t12, b11, b12) and box(c1, c2, r, t21, t22, b21, b22) and int(t11, t12, b11, b12, t21, t22, b21, b22)))\",\n",
    "    \"all i. ((y = out) -> (Circle(i, c1, c2, r) and Rect(i, t11, t12, b11, b12) and box(c1, c2, r, t21, t22, b21, b22) and out(t11, t12, b11, b12, t21, t22, b21, b22)))\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicates = {\n",
    "    \"Circle\": CircleDetector(),\n",
    "    \"Rect\": RectangleDetector(),\n",
    "    \"box\": BoundingBox(),\n",
    "    \"in\": Inside(),\n",
    "    \"out\": Outside(),\n",
    "    \"int\": Intersect()\n",
    "}\n",
    "\n",
    "loader = LoaderWrapper(loader=train_dataloader, variables=[\"i\"], targets=[\"y\"])\n",
    "\n",
    "rule_to_loader = {rule: [loader] for rule in learning_rules } \n",
    "\n",
    "quantifier_imp = {\"forall\" : \"pmean_error\"}\n",
    "\n",
    "connective_imp = {\"eq\": \"tan\"}\n",
    "\n",
    "constants = { \n",
    "    \"in\" : torch.tensor([0.]),\n",
    "    \"int\" : torch.tensor([1.]),\n",
    "    \"out\" : torch.tensor([2.]),\n",
    "}\n",
    "\n",
    "kb = KnowledgeBase(\n",
    "    predicates=predicates,\n",
    "    ancillary_rules=[],\n",
    "    learning_rules=learning_rules,\n",
    "    rule_to_data_loader_mapping=rule_to_loader,\n",
    "    quantifier_impls=quantifier_imp,\n",
    "    connective_impls=connective_imp,\n",
    "    constant_mapping=constants\n",
    ")\n",
    "\n",
    "[ str(rule) for rule in kb.rules ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kb.optimize(num_epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computation Graph and Intermediate Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kb.declarations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kb.rules[0].visitor.intermediate_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(test_dataloader))\n",
    "\n",
    "var_mapping = {}\n",
    "\n",
    "kb.partition_data(var_mapping,batch, loader )\n",
    "\n",
    "kb.rules[0].comp_graph(var_mapping)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
