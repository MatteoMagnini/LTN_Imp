{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Processing\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from examples.generator import generate_balanced_dataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Torch \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "# LTN\n",
    "from nltk.sem.logic import Expression\n",
    "from ltn_imp.automation.knowledge_base import KnowledgeBase\n",
    "from ltn_imp.automation.data_loaders import LoaderWrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(generate_balanced_dataset(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = [item for item in data[0]]\n",
    "images = []\n",
    "for path in image_paths:\n",
    "    try:\n",
    "        img = Image.open(path).convert('RGB')  # Convert to RGB to ensure consistency\n",
    "        img = np.array(img)\n",
    "        img_tensor = torch.tensor(img, dtype=torch.float32)  # Convert to PyTorch tensor\n",
    "        images.append(img_tensor)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading image {path}: {e}\")\n",
    "        \n",
    "labels = torch.tensor(data[1], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mv/_dg3pqgn2zdf7f95_1dg07rw0000gn/T/ipykernel_39594/3823677747.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.images = torch.stack([torch.tensor(image).permute(2, 0, 1) for image in images])\n",
      "/var/folders/mv/_dg3pqgn2zdf7f95_1dg07rw0000gn/T/ipykernel_39594/3823677747.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.labels = torch.tensor(labels).float()\n"
     ]
    }
   ],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, images, labels):\n",
    "        # Convert the list of images to a tensor and permute dimensions to [batch_size, channels, height, width]\n",
    "        self.images = torch.stack([torch.tensor(image).permute(2, 0, 1) for image in images])\n",
    "        self.labels = torch.tensor(labels).float()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        return image, label\n",
    "    \n",
    "batch_size = 25\n",
    "\n",
    "# Split the data into training and test sets\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(images,labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create the training dataset\n",
    "train_dataset = ImageDataset(train_data, train_labels)\n",
    "\n",
    "# Create the test dataset\n",
    "test_dataset = ImageDataset(test_data, test_labels)\n",
    "\n",
    "# Create the training dataloader\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Create the test dataloader\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='0'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(labels).value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training images: 240\n",
      "Number of training labels: 240\n",
      "Number of test images: 60\n",
      "Number of test labels: 60\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of training images: {len(train_data)}\")\n",
    "print(f\"Number of training labels: {len(train_labels)}\")\n",
    "print(f\"Number of test images: {len(test_data)}\")\n",
    "print(f\"Number of test labels: {len(test_labels)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x15656c6b0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_data[0].numpy().astype(np.uint8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CircleDetector(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CircleDetector, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "        self.fc1 = nn.Linear(in_features=64*16*16, out_features=128)\n",
    "        self.bn_fc1 = nn.BatchNorm1d(128)\n",
    "        self.fc2 = nn.Linear(in_features=128, out_features=3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.bn1(self.conv1(x)))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.leaky_relu(self.bn2(self.conv2(x)))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.leaky_relu(self.bn3(self.conv3(x)))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.leaky_relu(self.bn_fc1(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        c_x, c_y, r = torch.tanh(x[:, 0]), torch.tanh(x[:, 1]), torch.sigmoid(x[:, 2])\n",
    "        return c_x, c_y, r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RectangleDetector(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RectangleDetector, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "        self.fc1 = nn.Linear(in_features=64*16*16, out_features=128)\n",
    "        self.bn_fc1 = nn.BatchNorm1d(128)\n",
    "        self.fc2 = nn.Linear(in_features=128, out_features=4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.bn1(self.conv1(x)))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.leaky_relu(self.bn2(self.conv2(x)))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.leaky_relu(self.bn3(self.conv3(x)))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.leaky_relu(self.bn_fc1(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        t_x, t_y,b_x, b_y = torch.tanh(x[:, 0]), torch.tanh(x[:, 1]), torch.tanh(x[:, 2]), torch.tanh(x[:, 3])\n",
    "        return t_x, t_y, b_x, b_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class BoundingBox(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BoundingBox, self).__init__()\n",
    "\n",
    "    def forward(self, c1, c2, r, t21=None, t22=None, b21=None, b22=None):\n",
    "        if t21 is None and t22 is None and b21 is None and b22 is None:\n",
    "            t21 = c1 - r\n",
    "            t22 = c2 - r\n",
    "            b21 = c1 + r\n",
    "            b22 = c2 + r\n",
    "            return t21, t22, b21, b22\n",
    "        else:\n",
    "            t21_check = 1 - torch.tanh(torch.abs(t21 - (c1 - r)))**2\n",
    "            t22_check = 1 - torch.tanh(torch.abs(t22 - (c2 - r)))**2\n",
    "            b21_check = 1 - torch.tanh(torch.abs(b21 - (c1 + r)))**2\n",
    "            b22_check = 1 - torch.tanh(torch.abs(b22 - (c2 + r)))**2\n",
    "            return t21_check * t22_check * b21_check * b22_check\n",
    "\n",
    "    def __call__(self, *args):\n",
    "        return self.forward(*args)\n",
    "\n",
    "class Inside(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Inside, self).__init__()\n",
    "\n",
    "    def forward(self, t11, t12, b11, b12, t21, t22, b21, b22):\n",
    "        smooth_lt_t11_t21 = torch.sigmoid(10 * (t21 - t11))\n",
    "        smooth_lt_t12_t22 = torch.sigmoid(10 * (t22 - t12))\n",
    "        smooth_lt_b11_b21 = torch.sigmoid(10 * (b21 - b11))\n",
    "        smooth_lt_b12_b22 = torch.sigmoid(10 * (b22 - b12))\n",
    "        return smooth_lt_t11_t21 * smooth_lt_t12_t22 * smooth_lt_b11_b21 * smooth_lt_b12_b22\n",
    "\n",
    "    def __call__(self, *args):\n",
    "        return self.forward(*args)\n",
    "\n",
    "class Outside(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Outside, self).__init__()\n",
    "\n",
    "    def forward(self, t11, t12, b11, b12, t21, t22, b21, b22):\n",
    "        smooth_gt_t11_t21 = torch.sigmoid(10 * (t11 - t21))\n",
    "        smooth_gt_t12_t22 = torch.sigmoid(10 * (t12 - t22))\n",
    "        smooth_gt_b11_b21 = torch.sigmoid(10 * (b11 - b21))\n",
    "        smooth_gt_b12_b22 = torch.sigmoid(10 * (b12 - b22))\n",
    "        return smooth_gt_t11_t21 * smooth_gt_t12_t22 * smooth_gt_b11_b21 * smooth_gt_b12_b22\n",
    "\n",
    "    def __call__(self, *args):\n",
    "        return self.forward(*args)\n",
    "\n",
    "class Intersect(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Intersect, self).__init__()\n",
    "\n",
    "    def forward(self, t11, t12, b11, b12, t21, t22, b21, b22):\n",
    "        smooth_lt_t11_t21 = torch.sigmoid(10 * (t21 - t11))\n",
    "        smooth_lt_t12_t22 = torch.sigmoid(10 * (t22 - t12))\n",
    "        smooth_lt_b11_b21 = torch.sigmoid(10 * (b21 - b11))\n",
    "        smooth_lt_b12_b22 = torch.sigmoid(10 * (b22 - b12))\n",
    "        smooth_gt_t11_t21 = torch.sigmoid(10 * (t11 - t21))\n",
    "        smooth_gt_t12_t22 = torch.sigmoid(10 * (t12 - t22))\n",
    "        smooth_gt_b11_b21 = torch.sigmoid(10 * (b11 - b21))\n",
    "        smooth_gt_b12_b22 = torch.sigmoid(10 * (b12 - b22))\n",
    "        inside = smooth_lt_t11_t21 * smooth_lt_t12_t22 * smooth_lt_b11_b21 * smooth_lt_b12_b22\n",
    "        outside = smooth_gt_t11_t21 * smooth_gt_t12_t22 * smooth_gt_b11_b21 * smooth_gt_b12_b22\n",
    "        return 1 - (inside + outside - inside * outside)  # Smooth approximation of NOT OR (XOR)\n",
    "\n",
    "    def __call__(self, *args):\n",
    "        return self.forward(*args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_accuracy(circle_model, rect_model, bounding_box, inside_model, outside_model, intersect_model, test_dataloader, device):\n",
    "    # Set models to evaluation mode\n",
    "    circle_model.eval()\n",
    "    rect_model.eval()\n",
    "    bounding_box.eval()\n",
    "    inside_model.eval()\n",
    "    outside_model.eval()\n",
    "    intersect_model.eval()\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    class_correct = [0, 0, 0]\n",
    "    class_total = [0, 0, 0]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (img_batch, label_batch) in enumerate(test_dataloader):\n",
    "            img_batch, label_batch = img_batch.to(device), label_batch.to(device)\n",
    "            \n",
    "            # Predict the circle parameters\n",
    "            c_x, c_y, r = circle_model(img_batch)\n",
    "\n",
    "            # Get the bounding box for the predicted circle\n",
    "            t21, t22, b21, b22 = bounding_box(c_x, c_y, r)\n",
    "            \n",
    "            # Get the bounding box for the true circle\n",
    "            t11, t12, b11, b12 = rect_model(img_batch)\n",
    "            \n",
    "            for i in range(len(img_batch)):\n",
    "                # Extract the true one-hot encoded label\n",
    "                true_class = int(label_batch[i].item())\n",
    "                \n",
    "                # Compute probabilities for being inside, outside, and intersecting\n",
    "                inside_prob = inside_model(t11[i], t12[i], b11[i], b12[i], t21[i], t22[i], b21[i], b22[i])\n",
    "                outside_prob = outside_model(t11[i], t12[i], b11[i], b12[i], t21[i], t22[i], b21[i], b22[i])\n",
    "                intersect_prob = intersect_model(t11[i], t12[i], b11[i], b12[i], t21[i], t22[i], b21[i], b22[i])\n",
    "                \n",
    "                # Stack probabilities to form a tensor\n",
    "                class_probs = torch.tensor([inside_prob, intersect_prob, outside_prob,], device=device)\n",
    "                predicted_class = torch.argmax(class_probs).item()\n",
    "                \n",
    "                # Update overall accuracy\n",
    "                if predicted_class == true_class:\n",
    "                    correct += 1\n",
    "                    class_correct[true_class] += 1\n",
    "                class_total[true_class] += 1\n",
    "                total += 1\n",
    "\n",
    "    accuracy = correct / total\n",
    "    class_accuracies = [class_correct[i] / class_total[i] if class_total[i] > 0 else 0 for i in range(3)]\n",
    "    \n",
    "    # Debug: print class-wise accuracies\n",
    "    for i, class_acc in enumerate(class_accuracies):\n",
    "        print(f\"Accuracy for class {i}: {class_acc * 100:.2f}%\")\n",
    "    print(f\"Overall accuracy: {accuracy * 100:.2f}%\")\n",
    "    \n",
    "    # Set models back to training mode\n",
    "    circle_model.train()\n",
    "    rect_model.train()\n",
    "    bounding_box.train()\n",
    "    inside_model.train()\n",
    "    outside_model.train()\n",
    "    intersect_model.train()\n",
    "\n",
    "    return accuracy, class_accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ancillary_rules = [\n",
    "#     \"forall c1 c2 r t21 t22 b21 b22. box(c1, c2, r, t21, t22, b21, b22) <-> (t21 = c1 - r and t22 = c2 - r and b21 = c1 + r and b22 = c2 + r)\",\n",
    "#     \"forall t11 t12 b11 b12 t21 t22 b21 b22. in(t11, t12, b11, b12, t21, t22, b21, b22) <-> (t11 >= t21 and t12 >= t22 and b11 <= b21 and b12 <= b22)\",\n",
    "#     \"forall t11 t12 b11 b12 t21 t22 b21 b22. out(t11, t12, b11, b12, t21, t22, b21, b22) <-> (t11 > b21 and t12 > b22 and b11 < t21 and b12 < t22)\",\n",
    "#     \"forall t11 t12 b11 b12 t21 t22 b21 b22. int(t11, t12, b11, b12, t21, t22, b21, b22) <-> (not out(t11, t12, b11, b12, t21, t22, b21, b22) and not in(t11, t12, b11, b12, t21, t22, b21, b22))\"\n",
    "# ]\n",
    "\n",
    "learning_rules = [\n",
    "    \"all i. ((y = in) -> (Circle(i, c1, c2, r) and Rect(i, t11, t12, b11, b12) and box(c1, c2, r, t21, t22, b21, b22) and in(t11, t12, b11, b12, t21, t22, b21, b22)))\",\n",
    "    \"all i. ((y = int) -> (Circle(i, c1, c2, r) and Rect(i, t11, t12, b11, b12) and box(c1, c2, r, t21, t22, b21, b22) and int(t11, t12, b11, b12, t21, t22, b21, b22)))\",\n",
    "    \"all i. ((y = out) -> (Circle(i, c1, c2, r) and Rect(i, t11, t12, b11, b12) and box(c1, c2, r, t21, t22, b21, b22) and out(t11, t12, b11, b12, t21, t22, b21, b22)))\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['all i.((y = in) -> (Circle(i,c1,c2,r) & Rect(i,t11,t12,b11,b12) & box(c1,c2,r,t21,t22,b21,b22) & in(t11,t12,b11,b12,t21,t22,b21,b22)))',\n",
       " 'all i.((y = int) -> (Circle(i,c1,c2,r) & Rect(i,t11,t12,b11,b12) & box(c1,c2,r,t21,t22,b21,b22) & int(t11,t12,b11,b12,t21,t22,b21,b22)))',\n",
       " 'all i.((y = out) -> (Circle(i,c1,c2,r) & Rect(i,t11,t12,b11,b12) & box(c1,c2,r,t21,t22,b21,b22) & out(t11,t12,b11,b12,t21,t22,b21,b22)))']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "circle = CircleDetector()\n",
    "rectangle = RectangleDetector()\n",
    "\n",
    "predicates = {\n",
    "    \"Circle\": circle,\n",
    "    \"Rect\": rectangle,\n",
    "    \"box\": BoundingBox(),\n",
    "    \"in\": Inside(),\n",
    "    \"out\": Outside(),\n",
    "    \"int\": Intersect()\n",
    "}\n",
    "\n",
    "loader = LoaderWrapper(loader=train_dataloader, variables=[\"i\"], targets=[\"y\"])\n",
    "\n",
    "rule_to_loader = {rule: [loader] for rule in learning_rules } \n",
    "\n",
    "quantifier_imp = {\"forall\" : \"pmean_error\"}\n",
    "\n",
    "connective_imp = {\"eq\": \"tan\"}\n",
    "\n",
    "constants = { \n",
    "    \"in\" : torch.tensor([0.]),\n",
    "    \"int\" : torch.tensor([1.]),\n",
    "    \"out\" : torch.tensor([2.]),\n",
    "}\n",
    "\n",
    "kb = KnowledgeBase(\n",
    "    predicates=predicates,\n",
    "    ancillary_rules=[],\n",
    "    learning_rules=learning_rules,\n",
    "    rule_to_data_loader_mapping=rule_to_loader,\n",
    "    quantifier_impls=quantifier_imp,\n",
    "    connective_impls=connective_imp,\n",
    "    constant_mapping=constants\n",
    ")\n",
    "\n",
    "[ str(rule) for rule in kb.rules ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for class 0: 0.00%\n",
      "Accuracy for class 1: 100.00%\n",
      "Accuracy for class 2: 0.00%\n",
      "Overall accuracy: 25.00%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.25, [0.0, 1.0, 0.0])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_accuracy(circle,rectangle,BoundingBox(), Inside(), Outside(), Intersect(), test_dataloader, torch.device(\"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['all i.((y = in) -> (Circle(i,c1,c2,r) & Rect(i,t11,t12,b11,b12) & box(c1,c2,r,t21,t22,b21,b22) & in(t11,t12,b11,b12,t21,t22,b21,b22)))', 'all i.((y = int) -> (Circle(i,c1,c2,r) & Rect(i,t11,t12,b11,b12) & box(c1,c2,r,t21,t22,b21,b22) & int(t11,t12,b11,b12,t21,t22,b21,b22)))', 'all i.((y = out) -> (Circle(i,c1,c2,r) & Rect(i,t11,t12,b11,b12) & box(c1,c2,r,t21,t22,b21,b22) & out(t11,t12,b11,b12,t21,t22,b21,b22)))']\n",
      "Rule Outputs:  [tensor(0.6102, grad_fn=<RsubBackward1>), tensor(0.7344, grad_fn=<RsubBackward1>), tensor(0.5617, grad_fn=<RsubBackward1>)]\n",
      "Epoch 1/51, Loss: 0.3717721700668335\n",
      "\n",
      "['all i.((y = in) -> (Circle(i,c1,c2,r) & Rect(i,t11,t12,b11,b12) & box(c1,c2,r,t21,t22,b21,b22) & in(t11,t12,b11,b12,t21,t22,b21,b22)))', 'all i.((y = int) -> (Circle(i,c1,c2,r) & Rect(i,t11,t12,b11,b12) & box(c1,c2,r,t21,t22,b21,b22) & int(t11,t12,b11,b12,t21,t22,b21,b22)))', 'all i.((y = out) -> (Circle(i,c1,c2,r) & Rect(i,t11,t12,b11,b12) & box(c1,c2,r,t21,t22,b21,b22) & out(t11,t12,b11,b12,t21,t22,b21,b22)))']\n",
      "Rule Outputs:  [tensor(0.6654, grad_fn=<RsubBackward1>), tensor(0.7214, grad_fn=<RsubBackward1>), tensor(0.5617, grad_fn=<RsubBackward1>)]\n",
      "Epoch 11/51, Loss: 0.35669994354248047\n",
      "\n",
      "['all i.((y = in) -> (Circle(i,c1,c2,r) & Rect(i,t11,t12,b11,b12) & box(c1,c2,r,t21,t22,b21,b22) & in(t11,t12,b11,b12,t21,t22,b21,b22)))', 'all i.((y = int) -> (Circle(i,c1,c2,r) & Rect(i,t11,t12,b11,b12) & box(c1,c2,r,t21,t22,b21,b22) & int(t11,t12,b11,b12,t21,t22,b21,b22)))', 'all i.((y = out) -> (Circle(i,c1,c2,r) & Rect(i,t11,t12,b11,b12) & box(c1,c2,r,t21,t22,b21,b22) & out(t11,t12,b11,b12,t21,t22,b21,b22)))']\n",
      "Rule Outputs:  [tensor(0.6654, grad_fn=<RsubBackward1>), tensor(0.7214, grad_fn=<RsubBackward1>), tensor(0.5617, grad_fn=<RsubBackward1>)]\n",
      "Epoch 21/51, Loss: 0.3566998243331909\n",
      "\n",
      "['all i.((y = in) -> (Circle(i,c1,c2,r) & Rect(i,t11,t12,b11,b12) & box(c1,c2,r,t21,t22,b21,b22) & in(t11,t12,b11,b12,t21,t22,b21,b22)))', 'all i.((y = int) -> (Circle(i,c1,c2,r) & Rect(i,t11,t12,b11,b12) & box(c1,c2,r,t21,t22,b21,b22) & int(t11,t12,b11,b12,t21,t22,b21,b22)))', 'all i.((y = out) -> (Circle(i,c1,c2,r) & Rect(i,t11,t12,b11,b12) & box(c1,c2,r,t21,t22,b21,b22) & out(t11,t12,b11,b12,t21,t22,b21,b22)))']\n",
      "Rule Outputs:  [tensor(0.6654, grad_fn=<RsubBackward1>), tensor(0.7214, grad_fn=<RsubBackward1>), tensor(0.5617, grad_fn=<RsubBackward1>)]\n",
      "Epoch 31/51, Loss: 0.3566998243331909\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mkb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m51\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0001\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Developer/LTN_Imp/ltn_imp/automation/knowledge_base.py:104\u001b[0m, in \u001b[0;36mKnowledgeBase.optimize\u001b[0;34m(self, num_epochs, log_steps, lr)\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m    103\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss(rule_outputs)\n\u001b[0;32m--> 104\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m%\u001b[39m log_steps \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/Developer/LTN_Imp/.venv/lib/python3.12/site-packages/torch/_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    524\u001b[0m     )\n\u001b[0;32m--> 525\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Developer/LTN_Imp/.venv/lib/python3.12/site-packages/torch/autograd/__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Developer/LTN_Imp/.venv/lib/python3.12/site-packages/torch/autograd/graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    745\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "kb.optimize(num_epochs=51, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_accuracy(circle,rectangle,BoundingBox(), Inside(), Outside(), Intersect(), test_dataloader, torch.device(\"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kb.declarations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computation Graph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(test_dataloader))\n",
    "\n",
    "var_mapping = {}\n",
    "\n",
    "kb.partition_data(var_mapping,batch, loader )\n",
    "\n",
    "kb.rules[0].comp_graph(var_mapping)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
