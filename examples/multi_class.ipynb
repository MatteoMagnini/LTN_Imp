{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import ltn\n",
    "from ltn_imp.automation.knowledge_base import KnowledgeBase\n",
    "from ltn_imp.automation.data_loaders import LoaderWrapper\n",
    "from ltn_imp.fuzzy_operators.aggregators import SatAgg\n",
    "from ltn_imp.parsing.parser import LTNConverter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37mPoe =>\u001b[0m \u001b[94mmkdir -p examples/datasets\u001b[0m\n",
      "\u001b[37mPoe =>\u001b[0m \u001b[94mcurl -L -o examples/datasets/iris_training.csv https://raw.githubusercontent.com/tommasocarraro/LTNtorch/main/examples/datasets/iris_training.csv\u001b[0m\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  2218  100  2218    0     0  43671      0 --:--:-- --:--:-- --:--:-- 44360\n",
      "\u001b[37mPoe =>\u001b[0m \u001b[94mcurl -L -o examples/datasets/iris_test.csv https://raw.githubusercontent.com/tommasocarraro/LTNtorch/main/examples/datasets/iris_test.csv\u001b[0m\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100   598  100   598    0     0   9916      0 --:--:-- --:--:-- --:--:--  9966\n"
     ]
    }
   ],
   "source": [
    "!poetry run poe download-datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"datasets/iris_training.csv\")\n",
    "test_data = pd.read_csv(\"datasets/iris_test.csv\")\n",
    "\n",
    "train_labels = train_data.pop(\"species\")\n",
    "test_labels = test_data.pop(\"species\")\n",
    "\n",
    "train_data = torch.tensor(train_data.to_numpy()).float()\n",
    "test_data = torch.tensor(test_data.to_numpy()).float()\n",
    "train_labels = torch.tensor(train_labels.to_numpy()).long()\n",
    "test_labels = torch.tensor(test_labels.to_numpy()).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "0    42\n",
       "2    42\n",
       "1    36\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(train_labels).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we define predicate P\n",
    "class MLP(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    This model returns the logits for the classes given an input example. It does not compute the softmax, so the output\n",
    "    are not normalized.\n",
    "    This is done to separate the accuracy computation from the satisfaction level computation. Go through the example\n",
    "    to understand it.\n",
    "    \"\"\"\n",
    "    def __init__(self, layer_sizes=(4, 16, 16, 8, 3)):\n",
    "        super(MLP, self).__init__()\n",
    "        self.elu = torch.nn.ELU()\n",
    "        self.dropout = torch.nn.Dropout(0.2)\n",
    "        self.linear_layers = torch.nn.ModuleList([torch.nn.Linear(layer_sizes[i - 1], layer_sizes[i])\n",
    "                                                  for i in range(1, len(layer_sizes))])\n",
    "\n",
    "    def forward(self, x, training=False):\n",
    "        \"\"\"\n",
    "        Method which defines the forward phase of the neural network for our multi class classification task.\n",
    "        In particular, it returns the logits for the classes given an input example.\n",
    "\n",
    "        :param x: the features of the example\n",
    "        :param training: whether the network is in training mode (dropout applied) or validation mode (dropout not applied)\n",
    "        :return: logits for example x\n",
    "        \"\"\"\n",
    "        for layer in self.linear_layers[:-1]:\n",
    "            x = self.elu(layer(x))\n",
    "            if training:\n",
    "                x = self.dropout(x)\n",
    "        logits = self.linear_layers[-1](x)\n",
    "        return logits\n",
    "\n",
    "\n",
    "class LogitsToPredicate(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    This model has inside a logits model, that is a model which compute logits for the classes given an input example x.\n",
    "    The idea of this model is to keep logits and probabilities separated. The logits model returns the logits for an example,\n",
    "    while this model returns the probabilities given the logits model.\n",
    "\n",
    "    In particular, it takes as input an example x and a class label l. It applies the logits model to x to get the logits.\n",
    "    Then, it applies a softmax function to get the probabilities per classes. Finally, it returns only the probability related\n",
    "    to the given class l.\n",
    "    \"\"\"\n",
    "    def __init__(self, logits_model):\n",
    "        super(LogitsToPredicate, self).__init__()\n",
    "        self.logits_model = logits_model\n",
    "        self.softmax = torch.nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x, l, training=True):\n",
    "        logits = self.logits_model(x, training=training)\n",
    "        probs = self.softmax(logits)\n",
    "        out = torch.sum(probs * l, dim=1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader(object):\n",
    "    def __init__(self,\n",
    "                 data,\n",
    "                 labels,\n",
    "                 batch_size=1,\n",
    "                 shuffle=True):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(self.data.shape[0] / self.batch_size))\n",
    "\n",
    "    def __iter__(self):\n",
    "        n = self.data.shape[0]\n",
    "        idxlist = list(range(n))\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(idxlist)\n",
    "\n",
    "        for _, start_idx in enumerate(range(0, n, self.batch_size)):\n",
    "            end_idx = min(start_idx + self.batch_size, n)\n",
    "            data = self.data[idxlist[start_idx:end_idx]]\n",
    "            labels = self.labels[idxlist[start_idx:end_idx]]\n",
    "\n",
    "            yield data, labels\n",
    "\n",
    "# create train and test loader\n",
    "train_loader = DataLoader(train_data, train_labels, 64, shuffle=True)\n",
    "test_loader = DataLoader(test_data, test_labels, 64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(loader, model, num_classes):\n",
    "    class_correct = np.zeros(num_classes)\n",
    "    class_total = np.zeros(num_classes)\n",
    "\n",
    "    for data, labels in loader:\n",
    "        predictions = model(data).detach().numpy()\n",
    "        predictions = np.argmax(predictions, axis=1)\n",
    "        labels = labels.numpy()  # Convert labels to numpy array\n",
    "\n",
    "        for i in range(num_classes):\n",
    "            class_mask = (labels == i)\n",
    "            class_correct[i] += np.sum(predictions[class_mask] == labels[class_mask])\n",
    "            class_total[i] += np.sum(class_mask)\n",
    "\n",
    "    class_accuracy = class_correct / class_total\n",
    "\n",
    "    # Print accuracy for each class\n",
    "    for i in range(num_classes):\n",
    "        print(f'Accuracy for class {i}: {class_accuracy[i]:.2f}')\n",
    "\n",
    "    # Compute and print general accuracy\n",
    "    overall_accuracy = np.sum(class_correct) / np.sum(class_total)\n",
    "    print(f'Overall accuracy: {overall_accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLP()\n",
    "model = LogitsToPredicate(mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for class 0: 0.00\n",
      "Accuracy for class 1: 0.00\n",
      "Accuracy for class 2: 1.00\n",
      "Overall accuracy: 0.35\n"
     ]
    }
   ],
   "source": [
    "compute_accuracy(train_loader, model = mlp, num_classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for class 0: 0.00\n",
      "Accuracy for class 1: 0.00\n",
      "Accuracy for class 2: 1.00\n",
      "Overall accuracy: 0.27\n"
     ]
    }
   ],
   "source": [
    "compute_accuracy(test_loader, model = mlp,num_classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['all x.((y = zero) -> Classifier(x,zero))', 'all x.((y = one) -> Classifier(x,one))', 'all x.((y = two) -> Classifier(x,two))']\n",
      "Results: [tensor(0.5630, grad_fn=<RsubBackward1>), tensor(0.6789, grad_fn=<RsubBackward1>), tensor(0.6382, grad_fn=<RsubBackward1>)]\n",
      "Loss: tensor(0.3764, grad_fn=<RsubBackward1>)\n",
      "\n",
      "['all x.((y = zero) -> Classifier(x,zero))', 'all x.((y = one) -> Classifier(x,one))', 'all x.((y = two) -> Classifier(x,two))']\n",
      "Results: [tensor(0.9093, grad_fn=<RsubBackward1>), tensor(0.7175, grad_fn=<RsubBackward1>), tensor(0.7699, grad_fn=<RsubBackward1>)]\n",
      "Loss: tensor(0.2168, grad_fn=<RsubBackward1>)\n",
      "\n",
      "['all x.((y = zero) -> Classifier(x,zero))', 'all x.((y = one) -> Classifier(x,one))', 'all x.((y = two) -> Classifier(x,two))']\n",
      "Results: [tensor(0.9572, grad_fn=<RsubBackward1>), tensor(0.7684, grad_fn=<RsubBackward1>), tensor(0.8068, grad_fn=<RsubBackward1>)]\n",
      "Loss: tensor(0.1759, grad_fn=<RsubBackward1>)\n",
      "\n",
      "['all x.((y = zero) -> Classifier(x,zero))', 'all x.((y = one) -> Classifier(x,one))', 'all x.((y = two) -> Classifier(x,two))']\n",
      "Results: [tensor(0.9064, grad_fn=<RsubBackward1>), tensor(0.8290, grad_fn=<RsubBackward1>), tensor(0.8559, grad_fn=<RsubBackward1>)]\n",
      "Loss: tensor(0.1400, grad_fn=<RsubBackward1>)\n",
      "\n",
      "['all x.((y = zero) -> Classifier(x,zero))', 'all x.((y = one) -> Classifier(x,one))', 'all x.((y = two) -> Classifier(x,two))']\n",
      "Results: [tensor(0.9670, grad_fn=<RsubBackward1>), tensor(0.9136, grad_fn=<RsubBackward1>), tensor(0.9161, grad_fn=<RsubBackward1>)]\n",
      "Loss: tensor(0.0721, grad_fn=<RsubBackward1>)\n",
      "\n",
      "['all x.((y = zero) -> Classifier(x,zero))', 'all x.((y = one) -> Classifier(x,one))', 'all x.((y = two) -> Classifier(x,two))']\n",
      "Results: [tensor(0.9935, grad_fn=<RsubBackward1>), tensor(0.8655, grad_fn=<RsubBackward1>), tensor(0.8741, grad_fn=<RsubBackward1>)]\n",
      "Loss: tensor(0.1064, grad_fn=<RsubBackward1>)\n",
      "\n",
      "['all x.((y = zero) -> Classifier(x,zero))', 'all x.((y = one) -> Classifier(x,one))', 'all x.((y = two) -> Classifier(x,two))']\n",
      "Results: [tensor(0.9850, grad_fn=<RsubBackward1>), tensor(0.8632, grad_fn=<RsubBackward1>), tensor(0.9747, grad_fn=<RsubBackward1>)]\n",
      "Loss: tensor(0.0808, grad_fn=<RsubBackward1>)\n",
      "\n",
      "['all x.((y = zero) -> Classifier(x,zero))', 'all x.((y = one) -> Classifier(x,one))', 'all x.((y = two) -> Classifier(x,two))']\n",
      "Results: [tensor(0.9939, grad_fn=<RsubBackward1>), tensor(0.9492, grad_fn=<RsubBackward1>), tensor(0.8794, grad_fn=<RsubBackward1>)]\n",
      "Loss: tensor(0.0756, grad_fn=<RsubBackward1>)\n",
      "\n",
      "['all x.((y = zero) -> Classifier(x,zero))', 'all x.((y = one) -> Classifier(x,one))', 'all x.((y = two) -> Classifier(x,two))']\n",
      "Results: [tensor(0.9840, grad_fn=<RsubBackward1>), tensor(0.9127, grad_fn=<RsubBackward1>), tensor(0.9461, grad_fn=<RsubBackward1>)]\n",
      "Loss: tensor(0.0599, grad_fn=<RsubBackward1>)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the rules\n",
    "expression_1 = \"all x. ((y = zero) -> Classifier(x, zero))\"\n",
    "expression_2 = \"all x. ((y = one) -> Classifier(x, one))\"\n",
    "expression_3 = \"all x. ((y = two) -> Classifier(x, two))\"\n",
    "\n",
    "rules = [expression_1, expression_2, expression_3]\n",
    "\n",
    "# Initialize the satisfaction aggregator and optimizer\n",
    "sat_agg = SatAgg()\n",
    "optimizer = torch.optim.Adam(list(model.parameters()), lr=0.001)\n",
    "converter = LTNConverter(predicates={\"Classifier\": model}, quantifier_impls={\"forall\": \"pmean_error\"})\n",
    "\n",
    "# Convert the rules\n",
    "rules = [converter(rule, process=False) for rule in rules]\n",
    "\n",
    "log_steps = 100\n",
    "# Training loop\n",
    "for epoch in range(801):\n",
    "\n",
    "    for batch in train_loader:\n",
    "\n",
    "        results = []\n",
    "\n",
    "        data, label = batch\n",
    "        \n",
    "        # Convert labels to one-hot encoding\n",
    "        label = torch.stack([torch.tensor([1., 0., 0.]) if l == 0 else torch.tensor([0., 1., 0.]) if l == 1 else torch.tensor([0., 0., 1.]) for l in label])\n",
    "\n",
    "        # Create variable mapping for the entire batch\n",
    "        var_mapping = {\"x\": data, \"y\": label, \"zero\": torch.tensor([1., 0., 0.]),\"one\": torch.tensor([0., 1., 0.]), \"two\": torch.tensor([0., 0., 1.])}\n",
    "\n",
    "        # Apply rules to the entire batch\n",
    "        for rule in rules:\n",
    "            results.append(rule(var_mapping))\n",
    "\n",
    "    # Calculate the loss\n",
    "    loss = 1- sat_agg(*results)\n",
    "\n",
    "    # Ensure loss is a tensor and connected to the computation graph\n",
    "    assert isinstance(loss, torch.Tensor), \"Loss is not a tensor\"\n",
    "    assert loss.grad_fn is not None, \"Loss has no grad_fn, indicating it is not connected to the computation graph\"\n",
    "\n",
    "    # Backpropagation\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Logging\n",
    "    if epoch % log_steps == 0:\n",
    "        print([str(rule) for rule in rules])\n",
    "        print(\"Results:\", results)\n",
    "        print(\"Loss:\", loss)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for class 0: 1.00\n",
      "Accuracy for class 1: 0.94\n",
      "Accuracy for class 2: 1.00\n",
      "Overall accuracy: 0.98\n"
     ]
    }
   ],
   "source": [
    "compute_accuracy(train_loader, model = mlp, num_classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for class 0: 1.00\n",
      "Accuracy for class 1: 0.93\n",
      "Accuracy for class 2: 1.00\n",
      "Overall accuracy: 0.97\n"
     ]
    }
   ],
   "source": [
    "compute_accuracy(test_loader,model = mlp, num_classes=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
