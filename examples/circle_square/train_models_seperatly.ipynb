{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T13:55:14.211011Z",
     "start_time": "2024-08-08T13:55:14.207988Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data Processing\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from examples.circle_square.generator import generate_balanced_dataset, draw_shapes\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from ltn_imp.automation.knowledge_base import KnowledgeBase\n",
    "from ltn_imp.automation.data_loaders import LoaderWrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce271d4",
   "metadata": {},
   "source": [
    "## Data Processing and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "967fcf7f9752f670",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T13:55:14.896083Z",
     "start_time": "2024-08-08T13:55:14.247538Z"
    }
   },
   "outputs": [],
   "source": [
    "data, metadata = generate_balanced_dataset(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9a55208b6363223",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T13:55:14.898971Z",
     "start_time": "2024-08-08T13:55:14.897058Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eee268618c7c6ecc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T13:55:14.901034Z",
     "start_time": "2024-08-08T13:55:14.899457Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>circle_center_x</th>\n",
       "      <th>circle_center_y</th>\n",
       "      <th>circle_radius</th>\n",
       "      <th>rect_tl_x</th>\n",
       "      <th>rect_tl_y</th>\n",
       "      <th>rect_br_x</th>\n",
       "      <th>rect_br_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>112</td>\n",
       "      <td>33</td>\n",
       "      <td>10</td>\n",
       "      <td>72</td>\n",
       "      <td>50</td>\n",
       "      <td>116</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>74</td>\n",
       "      <td>10</td>\n",
       "      <td>51</td>\n",
       "      <td>95</td>\n",
       "      <td>89</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>48</td>\n",
       "      <td>97</td>\n",
       "      <td>19</td>\n",
       "      <td>21</td>\n",
       "      <td>34</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>66</td>\n",
       "      <td>108</td>\n",
       "      <td>11</td>\n",
       "      <td>77</td>\n",
       "      <td>55</td>\n",
       "      <td>101</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>72</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>96</td>\n",
       "      <td>49</td>\n",
       "      <td>125</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>91</td>\n",
       "      <td>53</td>\n",
       "      <td>15</td>\n",
       "      <td>73</td>\n",
       "      <td>75</td>\n",
       "      <td>108</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>62</td>\n",
       "      <td>28</td>\n",
       "      <td>15</td>\n",
       "      <td>33</td>\n",
       "      <td>50</td>\n",
       "      <td>81</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>28</td>\n",
       "      <td>94</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>106</td>\n",
       "      <td>50</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>41</td>\n",
       "      <td>62</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "      <td>85</td>\n",
       "      <td>60</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>102</td>\n",
       "      <td>31</td>\n",
       "      <td>15</td>\n",
       "      <td>82</td>\n",
       "      <td>53</td>\n",
       "      <td>128</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     circle_center_x  circle_center_y  circle_radius  rect_tl_x  rect_tl_y  \\\n",
       "0                112               33             10         72         50   \n",
       "1                 49               74             10         51         95   \n",
       "2                 48               97             19         21         34   \n",
       "3                 66              108             11         77         55   \n",
       "4                 72               14             13         96         49   \n",
       "..               ...              ...            ...        ...        ...   \n",
       "145               91               53             15         73         75   \n",
       "146               62               28             15         33         50   \n",
       "147               28               94             11          5        106   \n",
       "148               41               62             18         19         85   \n",
       "149              102               31             15         82         53   \n",
       "\n",
       "     rect_br_x  rect_br_y  \n",
       "0          116          1  \n",
       "1           89         67  \n",
       "2           41          1  \n",
       "3          101         16  \n",
       "4          125         30  \n",
       "..         ...        ...  \n",
       "145        108         34  \n",
       "146         81         12  \n",
       "147         50         73  \n",
       "148         60         43  \n",
       "149        128         10  \n",
       "\n",
       "[150 rows x 7 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata = pd.DataFrame(metadata)\n",
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59cd3fd112be9b64",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T13:55:15.039399Z",
     "start_time": "2024-08-08T13:55:14.902001Z"
    }
   },
   "outputs": [],
   "source": [
    "image_paths = [item for item in data[0]]\n",
    "images = []\n",
    "\n",
    "for path in image_paths:\n",
    "    try:\n",
    "        img = Image.open(path).convert('RGB')  # Convert to RGB to ensure consistency\n",
    "        img = np.array(img)\n",
    "        img_tensor = torch.tensor(img, dtype=torch.float32)  # Convert to PyTorch tensor\n",
    "        images.append(img_tensor)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading image {path}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "615ce622",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T13:55:15.236196Z",
     "start_time": "2024-08-08T13:55:15.040175Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mv/_dg3pqgn2zdf7f95_1dg07rw0000gn/T/ipykernel_3856/445107885.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.images = torch.stack([torch.tensor(image).permute(2, 0, 1) for image in images])\n"
     ]
    }
   ],
   "source": [
    "class EvalDataset(Dataset):\n",
    "    def __init__(self, images, metadata):\n",
    "        self.images = torch.stack([torch.tensor(image).permute(2, 0, 1) for image in images])\n",
    "        self.metadata = torch.tensor(metadata).float()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        metadata = self.metadata[idx]\n",
    "        return image, metadata\n",
    "    \n",
    "batch_size = 25\n",
    "\n",
    "circle_metadata = metadata[[\"circle_center_x\",\"circle_center_y\", \"circle_radius\"]]\n",
    "\n",
    "rectangle_metadata = metadata[[\"rect_tl_x\",\t\"rect_tl_y\"\t,\"rect_br_x\"\t,\"rect_br_y\"]]\n",
    "\n",
    "train_images, test_images, train_circle_labels, test_circle_labels = train_test_split( images, circle_metadata.values, test_size=0.2, random_state=42)\n",
    "\n",
    "train_images, test_images, train_rect_labels, test_rect_labels = train_test_split(images, rectangle_metadata.values, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create the training and test datasets for circles\n",
    "train_circle_dataset = EvalDataset(train_images, train_circle_labels)\n",
    "test_circle_dataset = EvalDataset(test_images, test_circle_labels)\n",
    "\n",
    "# Create the training and test datasets for rectangles\n",
    "train_rect_dataset = EvalDataset(train_images, train_rect_labels)\n",
    "test_rect_dataset = EvalDataset(test_images, test_rect_labels)\n",
    "\n",
    "# Create the dataloaders\n",
    "batch_size = 25\n",
    "\n",
    "# Circle dataloaders\n",
    "train_circle_dataloader = DataLoader(train_circle_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_circle_dataloader = DataLoader(test_circle_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Rectangle dataloaders\n",
    "train_rect_dataloader = DataLoader(train_rect_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_rect_dataloader = DataLoader(test_rect_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "debee8d5",
   "metadata": {},
   "source": [
    "# Models and Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a4374e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T13:55:15.241611Z",
     "start_time": "2024-08-08T13:55:15.236809Z"
    }
   },
   "outputs": [],
   "source": [
    "class CircleDetector(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CircleDetector, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "        self.fc1 = nn.Linear(in_features=64*16*16, out_features=128)\n",
    "        self.bn_fc1 = nn.BatchNorm1d(128)\n",
    "        self.fc2 = nn.Linear(in_features=128, out_features=3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.bn1(self.conv1(x)))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.leaky_relu(self.bn2(self.conv2(x)))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.leaky_relu(self.bn3(self.conv3(x)))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.leaky_relu(self.bn_fc1(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        c_x, c_y, r = (x[:, 0]), (x[:, 1]), (x[:, 2])\n",
    "        return c_x, c_y, r\n",
    "class RectangleDetector(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RectangleDetector, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "        self.fc1 = nn.Linear(in_features=64*16*16, out_features=128)\n",
    "        self.bn_fc1 = nn.BatchNorm1d(128)\n",
    "        self.fc2 = nn.Linear(in_features=128, out_features=4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.bn1(self.conv1(x)))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.leaky_relu(self.bn2(self.conv2(x)))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.leaky_relu(self.bn3(self.conv3(x)))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.leaky_relu(self.bn_fc1(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        t_x, t_y,b_x, b_y = (x[:, 0]), (x[:, 1]), (x[:, 2]), (x[:, 3])\n",
    "        return t_x, t_y, b_x, b_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "365387f7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T13:55:15.247713Z",
     "start_time": "2024-08-08T13:55:15.242166Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_circle(model, dataloader, criterion, optimizer, num_epochs=25, device='cpu'):\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            c_x, c_y, r = model(inputs)\n",
    "            outputs = torch.stack((c_x, c_y, r), dim=1)\n",
    "            \n",
    "            # Calculate loss\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Backward pass and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "        epoch_loss = running_loss / len(dataloader.dataset)\n",
    "        print(f'Epoch {epoch}/{num_epochs - 1}, Loss: {epoch_loss:.4f}')\n",
    "\n",
    "def train_rect(model, dataloader, criterion, optimizer, num_epochs=25, device='cpu'):\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            tl_x, tl_y, br_x, br_y = model(inputs)\n",
    "            outputs = torch.stack((tl_x, tl_y, br_x, br_y), dim=1)\n",
    "            \n",
    "            # Calculate loss\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Backward pass and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "        epoch_loss = running_loss / len(dataloader.dataset)\n",
    "        print(f'Epoch {epoch}/{num_epochs - 1}, Loss: {epoch_loss:.4f}')\n",
    "\n",
    "\n",
    "def evaluate_model_circle(model, dataloader, device='cpu'):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            c_x, c_y, r = model(inputs)\n",
    "            preds = torch.stack((c_x, c_y, r), dim=1)\n",
    "\n",
    "            all_preds.append(preds.cpu().numpy())\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "\n",
    "    all_preds = np.concatenate(all_preds, axis=0)\n",
    "    all_labels = np.concatenate(all_labels, axis=0)\n",
    "\n",
    "    mae = mean_absolute_error(all_labels, all_preds)\n",
    "    print(f'Mean Absolute Error: {mae:.4f}')\n",
    "    return mae\n",
    "\n",
    "\n",
    "def evaluate_model_rect(model, dataloader, device='cpu'):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            tl_x, tl_y, br_x, br_y = model(inputs)\n",
    "            preds = torch.stack((tl_x, tl_y, br_x, br_y), dim=1)\n",
    "\n",
    "            all_preds.append(preds.cpu().numpy())\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "\n",
    "    all_preds = np.concatenate(all_preds, axis=0)\n",
    "    all_labels = np.concatenate(all_labels, axis=0)\n",
    "\n",
    "    mae = mean_absolute_error(all_labels, all_preds)\n",
    "    print(f'Mean Absolute Error: {mae:.4f}')\n",
    "    return mae\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2bda82",
   "metadata": {},
   "source": [
    "# Circle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd3fadb",
   "metadata": {},
   "source": [
    "# Rectangle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38a27e4",
   "metadata": {},
   "source": [
    "# LTN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70657a53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mv/_dg3pqgn2zdf7f95_1dg07rw0000gn/T/ipykernel_3856/1125484005.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.images = torch.stack([torch.tensor(image).permute(2, 0, 1) for image in images])\n"
     ]
    }
   ],
   "source": [
    "class EvalDataset(Dataset):\n",
    "    def __init__(self, images, metadata):\n",
    "        self.images = torch.stack([torch.tensor(image).permute(2, 0, 1) for image in images])\n",
    "        \n",
    "        # Unpack the metadata into separate variables\n",
    "        metadata_tensor = torch.tensor(metadata).float()\n",
    "        self.t_x, self.t_y, self.b_x, self.b_y = metadata_tensor[:, 0], metadata_tensor[:, 1], metadata_tensor[:, 2], metadata_tensor[:, 3]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        t_x, t_y, b_x, b_y = self.t_x[idx], self.t_y[idx], self.b_x[idx], self.b_y[idx]\n",
    "        return image, t_x, t_y, b_x, b_y\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "rectangle_metadata = metadata[[\"rect_tl_x\", \"rect_tl_y\", \"rect_br_x\", \"rect_br_y\"]]\n",
    "train_images, test_images, train_rect_labels, test_rect_labels = train_test_split(images, rectangle_metadata.values, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create the training and test datasets for rectangles\n",
    "train_rect_dataset = EvalDataset(train_images, train_rect_labels)\n",
    "test_rect_dataset = EvalDataset(test_images, test_rect_labels)\n",
    "\n",
    "train_rect_dataloader = DataLoader(train_rect_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_rect_dataloader = DataLoader(test_rect_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29cae1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_rect(model, dataloader, device='cpu'):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, t_x, t_y, b_x, b_y in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            t_x, t_y, b_x, b_y = t_x.to(device), t_y.to(device), b_x.to(device), b_y.to(device)\n",
    "            tl_x, tl_y, br_x, br_y = model(inputs)\n",
    "            preds = torch.stack((tl_x, tl_y, br_x, br_y), dim=1)\n",
    "            labels = torch.stack((t_x, t_y, b_x, b_y), dim=1)\n",
    "\n",
    "            all_preds.append(preds.cpu().numpy())\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "\n",
    "    all_preds = np.concatenate(all_preds, axis=0)\n",
    "    all_labels = np.concatenate(all_labels, axis=0)\n",
    "\n",
    "    mae = mean_absolute_error(all_labels, all_preds)\n",
    "    print(f'Mean Absolute Error: {mae:.4f}')\n",
    "    return mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14d54eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rect = RectangleDetector()\n",
    "\n",
    "expression_1 = \"all i. (Rect(i, t1, t2, b1, b2))\"\n",
    "expression_2 = \"all t1. ((t1 = t11) and (b1 = b11) and (t2 = t22) and (b2 = b22))\"\n",
    "\n",
    "learning_rules = [expression_1, expression_2]\n",
    "\n",
    "loader = LoaderWrapper(loader=train_rect_dataloader, variables=[\"i\"], targets=[\"t11\", \"t22\", \"b11\", \"b22\"])\n",
    "\n",
    "rule_to_data_loader_mapping = {\n",
    "    expression_1: [loader],\n",
    "    expression_2: [loader], \n",
    "}\n",
    "\n",
    "predicates = {\n",
    "    \"Rect\": rect\n",
    "}\n",
    "\n",
    "quantifier_impls = { \"forall\" : \"min\" }\n",
    "\n",
    "\n",
    "kb = KnowledgeBase(learning_rules = learning_rules, ancillary_rules=[], rule_to_data_loader_mapping=rule_to_data_loader_mapping, \n",
    "                   predicates=predicates, quantifier_impls=quantifier_impls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90139e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 76.7833\n",
      "\n",
      "['all i.Rect(i,t1,t2,b1,b2)', 'all t1.((t1 = t11) & (b1 = b11) & (t2 = t22) & (b2 = b22))']\n",
      "Rule Outputs:  [tensor(1., grad_fn=<AminBackward0>), tensor(0.3679, grad_fn=<AminBackward0>)]\n",
      "Epoch 1/5, Loss: 0.4469767212867737\n",
      "\n",
      "['all i.Rect(i,t1,t2,b1,b2)', 'all t1.((t1 = t11) & (b1 = b11) & (t2 = t22) & (b2 = b22))']\n",
      "Rule Outputs:  [tensor(1., grad_fn=<AminBackward0>), tensor(0.3679, grad_fn=<AminBackward0>)]\n",
      "Epoch 2/5, Loss: 0.4469767212867737\n",
      "\n",
      "['all i.Rect(i,t1,t2,b1,b2)', 'all t1.((t1 = t11) & (b1 = b11) & (t2 = t22) & (b2 = b22))']\n",
      "Rule Outputs:  [tensor(1., grad_fn=<AminBackward0>), tensor(0.3679, grad_fn=<AminBackward0>)]\n",
      "Epoch 3/5, Loss: 0.4469767212867737\n",
      "\n",
      "['all i.Rect(i,t1,t2,b1,b2)', 'all t1.((t1 = t11) & (b1 = b11) & (t2 = t22) & (b2 = b22))']\n",
      "Rule Outputs:  [tensor(1., grad_fn=<AminBackward0>), tensor(0.3679, grad_fn=<AminBackward0>)]\n",
      "Epoch 4/5, Loss: 0.4469767212867737\n",
      "\n",
      "['all i.Rect(i,t1,t2,b1,b2)', 'all t1.((t1 = t11) & (b1 = b11) & (t2 = t22) & (b2 = b22))']\n",
      "Rule Outputs:  [tensor(1., grad_fn=<AminBackward0>), tensor(0.3679, grad_fn=<AminBackward0>)]\n",
      "Epoch 5/5, Loss: 0.4469767212867737\n",
      "\n",
      "\n",
      "Mean Absolute Error: 313.4561\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float32(313.4561)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model_rect(rect, train_rect_dataloader, device='cpu')\n",
    "print()\n",
    "kb.optimize(num_epochs=5, lr=0.01, log_steps=1)\n",
    "print()\n",
    "evaluate_model_rect(rect, test_rect_dataloader, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec89d47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
