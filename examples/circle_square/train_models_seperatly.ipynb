{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T13:55:14.211011Z",
     "start_time": "2024-08-08T13:55:14.207988Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data Processing\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from examples.circle_square.generator import generate_balanced_dataset, draw_shapes\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from ltn_imp.automation.knowledge_base import KnowledgeBase\n",
    "from ltn_imp.automation.data_loaders import LoaderWrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce271d4",
   "metadata": {},
   "source": [
    "## Data Processing and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "967fcf7f9752f670",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T13:55:14.896083Z",
     "start_time": "2024-08-08T13:55:14.247538Z"
    }
   },
   "outputs": [],
   "source": [
    "data, metadata = generate_balanced_dataset(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9a55208b6363223",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T13:55:14.898971Z",
     "start_time": "2024-08-08T13:55:14.897058Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eee268618c7c6ecc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T13:55:14.901034Z",
     "start_time": "2024-08-08T13:55:14.899457Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>circle_center_x</th>\n",
       "      <th>circle_center_y</th>\n",
       "      <th>circle_radius</th>\n",
       "      <th>rect_tl_x</th>\n",
       "      <th>rect_tl_y</th>\n",
       "      <th>rect_br_x</th>\n",
       "      <th>rect_br_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>102</td>\n",
       "      <td>56</td>\n",
       "      <td>18</td>\n",
       "      <td>13</td>\n",
       "      <td>91</td>\n",
       "      <td>59</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29</td>\n",
       "      <td>63</td>\n",
       "      <td>17</td>\n",
       "      <td>81</td>\n",
       "      <td>86</td>\n",
       "      <td>101</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>45</td>\n",
       "      <td>85</td>\n",
       "      <td>11</td>\n",
       "      <td>22</td>\n",
       "      <td>122</td>\n",
       "      <td>65</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34</td>\n",
       "      <td>38</td>\n",
       "      <td>18</td>\n",
       "      <td>63</td>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>32</td>\n",
       "      <td>12</td>\n",
       "      <td>27</td>\n",
       "      <td>80</td>\n",
       "      <td>75</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>95</td>\n",
       "      <td>99</td>\n",
       "      <td>10</td>\n",
       "      <td>78</td>\n",
       "      <td>114</td>\n",
       "      <td>113</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>74</td>\n",
       "      <td>90</td>\n",
       "      <td>17</td>\n",
       "      <td>56</td>\n",
       "      <td>115</td>\n",
       "      <td>102</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>90</td>\n",
       "      <td>28</td>\n",
       "      <td>14</td>\n",
       "      <td>67</td>\n",
       "      <td>56</td>\n",
       "      <td>117</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>110</td>\n",
       "      <td>62</td>\n",
       "      <td>12</td>\n",
       "      <td>90</td>\n",
       "      <td>89</td>\n",
       "      <td>124</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>105</td>\n",
       "      <td>46</td>\n",
       "      <td>10</td>\n",
       "      <td>77</td>\n",
       "      <td>69</td>\n",
       "      <td>120</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     circle_center_x  circle_center_y  circle_radius  rect_tl_x  rect_tl_y  \\\n",
       "0                102               56             18         13         91   \n",
       "1                 29               63             17         81         86   \n",
       "2                 45               85             11         22        122   \n",
       "3                 34               38             18         63        103   \n",
       "4                 41               32             12         27         80   \n",
       "..               ...              ...            ...        ...        ...   \n",
       "145               95               99             10         78        114   \n",
       "146               74               90             17         56        115   \n",
       "147               90               28             14         67         56   \n",
       "148              110               62             12         90         89   \n",
       "149              105               46             10         77         69   \n",
       "\n",
       "     rect_br_x  rect_br_y  \n",
       "0           59         47  \n",
       "1          101         49  \n",
       "2           65        100  \n",
       "3          103         59  \n",
       "4           75         31  \n",
       "..         ...        ...  \n",
       "145        113         88  \n",
       "146        102         69  \n",
       "147        117         11  \n",
       "148        124         41  \n",
       "149        120         32  \n",
       "\n",
       "[150 rows x 7 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata = pd.DataFrame(metadata)\n",
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59cd3fd112be9b64",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T13:55:15.039399Z",
     "start_time": "2024-08-08T13:55:14.902001Z"
    }
   },
   "outputs": [],
   "source": [
    "image_paths = [item for item in data[0]]\n",
    "images = []\n",
    "\n",
    "for path in image_paths:\n",
    "    try:\n",
    "        img = Image.open(path).convert('RGB')  # Convert to RGB to ensure consistency\n",
    "        img = np.array(img)\n",
    "        img_tensor = torch.tensor(img, dtype=torch.float32)  # Convert to PyTorch tensor\n",
    "        images.append(img_tensor)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading image {path}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "615ce622",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T13:55:15.236196Z",
     "start_time": "2024-08-08T13:55:15.040175Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mv/_dg3pqgn2zdf7f95_1dg07rw0000gn/T/ipykernel_27484/445107885.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.images = torch.stack([torch.tensor(image).permute(2, 0, 1) for image in images])\n"
     ]
    }
   ],
   "source": [
    "class EvalDataset(Dataset):\n",
    "    def __init__(self, images, metadata):\n",
    "        self.images = torch.stack([torch.tensor(image).permute(2, 0, 1) for image in images])\n",
    "        self.metadata = torch.tensor(metadata).float()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        metadata = self.metadata[idx]\n",
    "        return image, metadata\n",
    "    \n",
    "batch_size = 25\n",
    "\n",
    "circle_metadata = metadata[[\"circle_center_x\",\"circle_center_y\", \"circle_radius\"]]\n",
    "\n",
    "rectangle_metadata = metadata[[\"rect_tl_x\",\t\"rect_tl_y\"\t,\"rect_br_x\"\t,\"rect_br_y\"]]\n",
    "\n",
    "train_images, test_images, train_circle_labels, test_circle_labels = train_test_split( images, circle_metadata.values, test_size=0.2, random_state=42)\n",
    "\n",
    "train_images, test_images, train_rect_labels, test_rect_labels = train_test_split(images, rectangle_metadata.values, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create the training and test datasets for circles\n",
    "train_circle_dataset = EvalDataset(train_images, train_circle_labels)\n",
    "test_circle_dataset = EvalDataset(test_images, test_circle_labels)\n",
    "\n",
    "# Create the training and test datasets for rectangles\n",
    "train_rect_dataset = EvalDataset(train_images, train_rect_labels)\n",
    "test_rect_dataset = EvalDataset(test_images, test_rect_labels)\n",
    "\n",
    "# Create the dataloaders\n",
    "batch_size = 25\n",
    "\n",
    "# Circle dataloaders\n",
    "train_circle_dataloader = DataLoader(train_circle_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_circle_dataloader = DataLoader(test_circle_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Rectangle dataloaders\n",
    "train_rect_dataloader = DataLoader(train_rect_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_rect_dataloader = DataLoader(test_rect_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "debee8d5",
   "metadata": {},
   "source": [
    "# Models and Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a4374e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T13:55:15.241611Z",
     "start_time": "2024-08-08T13:55:15.236809Z"
    }
   },
   "outputs": [],
   "source": [
    "class CircleDetector(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CircleDetector, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "        self.fc1 = nn.Linear(in_features=64*16*16, out_features=128)\n",
    "        self.bn_fc1 = nn.BatchNorm1d(128)\n",
    "        self.fc2 = nn.Linear(in_features=128, out_features=3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.bn1(self.conv1(x)))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.leaky_relu(self.bn2(self.conv2(x)))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.leaky_relu(self.bn3(self.conv3(x)))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.leaky_relu(self.bn_fc1(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        c_x, c_y, r = (x[:, 0]), (x[:, 1]), (x[:, 2])\n",
    "        return c_x, c_y, r\n",
    "class RectangleDetector(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RectangleDetector, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "        self.fc1 = nn.Linear(in_features=64*16*16, out_features=128)\n",
    "        self.bn_fc1 = nn.BatchNorm1d(128)\n",
    "        self.fc2 = nn.Linear(in_features=128, out_features=4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.bn1(self.conv1(x)))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.leaky_relu(self.bn2(self.conv2(x)))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.leaky_relu(self.bn3(self.conv3(x)))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.leaky_relu(self.bn_fc1(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        t_x, t_y,b_x, b_y = (x[:, 0]), (x[:, 1]), (x[:, 2]), (x[:, 3])\n",
    "        return t_x, t_y, b_x, b_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "365387f7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T13:55:15.247713Z",
     "start_time": "2024-08-08T13:55:15.242166Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_circle(model, dataloader, criterion, optimizer, num_epochs=25, device='cpu'):\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            c_x, c_y, r = model(inputs)\n",
    "            outputs = torch.stack((c_x, c_y, r), dim=1)\n",
    "            \n",
    "            # Calculate loss\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Backward pass and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "        epoch_loss = running_loss / len(dataloader.dataset)\n",
    "        print(f'Epoch {epoch}/{num_epochs - 1}, Loss: {epoch_loss:.4f}')\n",
    "\n",
    "def train_rect(model, dataloader, criterion, optimizer, num_epochs=25, device='cpu'):\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            tl_x, tl_y, br_x, br_y = model(inputs)\n",
    "            outputs = torch.stack((tl_x, tl_y, br_x, br_y), dim=1)\n",
    "            \n",
    "            # Calculate loss\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Backward pass and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "        epoch_loss = running_loss / len(dataloader.dataset)\n",
    "        print(f'Epoch {epoch}/{num_epochs - 1}, Loss: {epoch_loss:.4f}')\n",
    "\n",
    "\n",
    "def evaluate_model_circle(model, dataloader, device='cpu'):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            c_x, c_y, r = model(inputs)\n",
    "            preds = torch.stack((c_x, c_y, r), dim=1)\n",
    "\n",
    "            all_preds.append(preds.cpu().numpy())\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "\n",
    "    all_preds = np.concatenate(all_preds, axis=0)\n",
    "    all_labels = np.concatenate(all_labels, axis=0)\n",
    "\n",
    "    mae = mean_absolute_error(all_labels, all_preds)\n",
    "    print(f'Mean Absolute Error: {mae:.4f}')\n",
    "    return mae\n",
    "\n",
    "\n",
    "def evaluate_model_rect(model, dataloader, device='cpu'):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            tl_x, tl_y, br_x, br_y = model(inputs)\n",
    "            preds = torch.stack((tl_x, tl_y, br_x, br_y), dim=1)\n",
    "\n",
    "            all_preds.append(preds.cpu().numpy())\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "\n",
    "    all_preds = np.concatenate(all_preds, axis=0)\n",
    "    all_labels = np.concatenate(all_labels, axis=0)\n",
    "\n",
    "    mae = mean_absolute_error(all_labels, all_preds)\n",
    "    print(f'Mean Absolute Error: {mae:.4f}')\n",
    "    return mae\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2bda82",
   "metadata": {},
   "source": [
    "# Circle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd3fadb",
   "metadata": {},
   "source": [
    "# Rectangle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38a27e4",
   "metadata": {},
   "source": [
    "# LTN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70657a53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mv/_dg3pqgn2zdf7f95_1dg07rw0000gn/T/ipykernel_27484/1125484005.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.images = torch.stack([torch.tensor(image).permute(2, 0, 1) for image in images])\n"
     ]
    }
   ],
   "source": [
    "class EvalDataset(Dataset):\n",
    "    def __init__(self, images, metadata):\n",
    "        self.images = torch.stack([torch.tensor(image).permute(2, 0, 1) for image in images])\n",
    "        \n",
    "        # Unpack the metadata into separate variables\n",
    "        metadata_tensor = torch.tensor(metadata).float()\n",
    "        self.t_x, self.t_y, self.b_x, self.b_y = metadata_tensor[:, 0], metadata_tensor[:, 1], metadata_tensor[:, 2], metadata_tensor[:, 3]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        t_x, t_y, b_x, b_y = self.t_x[idx], self.t_y[idx], self.b_x[idx], self.b_y[idx]\n",
    "        return image, t_x, t_y, b_x, b_y\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "rectangle_metadata = metadata[[\"rect_tl_x\", \"rect_tl_y\", \"rect_br_x\", \"rect_br_y\"]]\n",
    "train_images, test_images, train_rect_labels, test_rect_labels = train_test_split(images, rectangle_metadata.values, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create the training and test datasets for rectangles\n",
    "train_rect_dataset = EvalDataset(train_images, train_rect_labels)\n",
    "test_rect_dataset = EvalDataset(test_images, test_rect_labels)\n",
    "\n",
    "train_rect_dataloader = DataLoader(train_rect_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_rect_dataloader = DataLoader(test_rect_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29cae1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_rect(model, dataloader, device='cpu'):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, t_x, t_y, b_x, b_y in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            t_x, t_y, b_x, b_y = t_x.to(device), t_y.to(device), b_x.to(device), b_y.to(device)\n",
    "            tl_x, tl_y, br_x, br_y = model(inputs)\n",
    "            preds = torch.stack((tl_x, tl_y, br_x, br_y), dim=1)\n",
    "            labels = torch.stack((t_x, t_y, b_x, b_y), dim=1)\n",
    "\n",
    "            all_preds.append(preds.cpu().numpy())\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "\n",
    "    all_preds = np.concatenate(all_preds, axis=0)\n",
    "    all_labels = np.concatenate(all_labels, axis=0)\n",
    "\n",
    "    mae = mean_absolute_error(all_labels, all_preds)\n",
    "    print(f'Mean Absolute Error: {mae:.4f}')\n",
    "    return mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14d54eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rect = RectangleDetector()\n",
    "\n",
    "expression_1 = \"all i. (Rect(i, t1, t2, b1, b2))\"\n",
    "expression_2 = \"all t1. ((t1 = t1) and (b1 = b11) and (t2 = t22) and (b2 = b22))\"\n",
    "\n",
    "learning_rules = [expression_1, expression_2]\n",
    "\n",
    "loader = LoaderWrapper(loader=train_rect_dataloader, variables=[\"i\"], targets=[\"t11\", \"t22\", \"b11\", \"b22\"])\n",
    "\n",
    "rule_to_data_loader_mapping = {\n",
    "    expression_1: [loader],\n",
    "    expression_2: [loader], \n",
    "}\n",
    "\n",
    "predicates = {\n",
    "    \"Rect\": rect\n",
    "}\n",
    "\n",
    "quantifier_impls = { \"forall\" : \"pmean_error\" }\n",
    "\n",
    "\n",
    "kb = KnowledgeBase(learning_rules = learning_rules, ancillary_rules=[], rule_to_data_loader_mapping=rule_to_data_loader_mapping, \n",
    "                   predicates=predicates, quantifier_impls=quantifier_impls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "90139e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 72.4398\n",
      "\n",
      "['∀ i.(Rect(i, t1, t2, b1, b2))', '∀ t1.(((t1 = t1) & ((b1 = b11) & ((t2 = t22) & (b2 = b22)))))']\n",
      "Rule Outputs:  [tensor(1., grad_fn=<RsubBackward1>), tensor(nan, grad_fn=<RsubBackward1>)]\n",
      "Epoch 1/5, Loss: nan\n",
      "\n",
      "['∀ i.(Rect(i, t1, t2, b1, b2))', '∀ t1.(((t1 = t1) & ((b1 = b11) & ((t2 = t22) & (b2 = b22)))))']\n",
      "Rule Outputs:  [tensor(1., grad_fn=<RsubBackward1>), tensor(nan, grad_fn=<RsubBackward1>)]\n",
      "Epoch 2/5, Loss: nan\n",
      "\n",
      "['∀ i.(Rect(i, t1, t2, b1, b2))', '∀ t1.(((t1 = t1) & ((b1 = b11) & ((t2 = t22) & (b2 = b22)))))']\n",
      "Rule Outputs:  [tensor(1., grad_fn=<RsubBackward1>), tensor(nan, grad_fn=<RsubBackward1>)]\n",
      "Epoch 3/5, Loss: nan\n",
      "\n",
      "['∀ i.(Rect(i, t1, t2, b1, b2))', '∀ t1.(((t1 = t1) & ((b1 = b11) & ((t2 = t22) & (b2 = b22)))))']\n",
      "Rule Outputs:  [tensor(1., grad_fn=<RsubBackward1>), tensor(nan, grad_fn=<RsubBackward1>)]\n",
      "Epoch 4/5, Loss: nan\n",
      "\n",
      "['∀ i.(Rect(i, t1, t2, b1, b2))', '∀ t1.(((t1 = t1) & ((b1 = b11) & ((t2 = t22) & (b2 = b22)))))']\n",
      "Rule Outputs:  [tensor(1., grad_fn=<RsubBackward1>), tensor(nan, grad_fn=<RsubBackward1>)]\n",
      "Epoch 5/5, Loss: nan\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m kb\u001b[38;5;241m.\u001b[39moptimize(num_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m, log_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m()\n\u001b[0;32m----> 5\u001b[0m \u001b[43mevaluate_model_rect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrect\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_rect_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[10], line 21\u001b[0m, in \u001b[0;36mevaluate_model_rect\u001b[0;34m(model, dataloader, device)\u001b[0m\n\u001b[1;32m     18\u001b[0m all_preds \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate(all_preds, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     19\u001b[0m all_labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate(all_labels, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 21\u001b[0m mae \u001b[38;5;241m=\u001b[39m \u001b[43mmean_absolute_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_preds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMean Absolute Error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmae\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m mae\n",
      "File \u001b[0;32m~/Developer/LTN_Imp/.venv/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m~/Developer/LTN_Imp/.venv/lib/python3.12/site-packages/sklearn/metrics/_regression.py:216\u001b[0m, in \u001b[0;36mmean_absolute_error\u001b[0;34m(y_true, y_pred, sample_weight, multioutput)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[1;32m    153\u001b[0m     {\n\u001b[1;32m    154\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    162\u001b[0m     y_true, y_pred, \u001b[38;5;241m*\u001b[39m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, multioutput\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muniform_average\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    163\u001b[0m ):\n\u001b[1;32m    164\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Mean absolute error regression loss.\u001b[39;00m\n\u001b[1;32m    165\u001b[0m \n\u001b[1;32m    166\u001b[0m \u001b[38;5;124;03m    Read more in the :ref:`User Guide <mean_absolute_error>`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;124;03m    0.85...\u001b[39;00m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m     y_type, y_true, y_pred, multioutput \u001b[38;5;241m=\u001b[39m \u001b[43m_check_reg_targets\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmultioutput\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    219\u001b[0m     check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[1;32m    220\u001b[0m     output_errors \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39maverage(np\u001b[38;5;241m.\u001b[39mabs(y_pred \u001b[38;5;241m-\u001b[39m y_true), weights\u001b[38;5;241m=\u001b[39msample_weight, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/Developer/LTN_Imp/.venv/lib/python3.12/site-packages/sklearn/metrics/_regression.py:113\u001b[0m, in \u001b[0;36m_check_reg_targets\u001b[0;34m(y_true, y_pred, multioutput, dtype, xp)\u001b[0m\n\u001b[1;32m    111\u001b[0m check_consistent_length(y_true, y_pred)\n\u001b[1;32m    112\u001b[0m y_true \u001b[38;5;241m=\u001b[39m check_array(y_true, ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m--> 113\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_true\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    116\u001b[0m     y_true \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mreshape(y_true, (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[0;32m~/Developer/LTN_Imp/.venv/lib/python3.12/site-packages/sklearn/utils/validation.py:1064\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1058\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1059\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1060\u001b[0m         \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[1;32m   1061\u001b[0m     )\n\u001b[1;32m   1063\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[0;32m-> 1064\u001b[0m     \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1065\u001b[0m \u001b[43m        \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1066\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1067\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1068\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1069\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1071\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[1;32m   1072\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[1;32m   1073\u001b[0m         \u001b[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001b[39;00m\n",
      "File \u001b[0;32m~/Developer/LTN_Imp/.venv/lib/python3.12/site-packages/sklearn/utils/validation.py:123\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 123\u001b[0m \u001b[43m_assert_all_finite_element_wise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Developer/LTN_Imp/.venv/lib/python3.12/site-packages/sklearn/utils/validation.py:172\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[0;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[1;32m    158\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    159\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    160\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    171\u001b[0m     )\n\u001b[0;32m--> 172\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN."
     ]
    }
   ],
   "source": [
    "evaluate_model_rect(rect, train_rect_dataloader, device='cpu')\n",
    "print()\n",
    "kb.optimize(num_epochs=5, lr=0.001, log_steps=1)\n",
    "print()\n",
    "evaluate_model_rect(rect, test_rect_dataloader, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec89d47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
