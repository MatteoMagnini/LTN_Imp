{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ltn_imp.automation.knowledge_base import KnowledgeBase\n",
    "import torch\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37mPoe =>\u001b[0m \u001b[94mmkdir -p examples/medical/datasets\u001b[0m\n",
      "\u001b[37mPoe =>\u001b[0m \u001b[94mcurl -L -o examples/medical/datasets/pima_indians_imputed.csv https://raw.githubusercontent.com/ChristelSirocchi/hybrid-ML/main/pima_indians_imputed.csv\u001b[0m\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 33428  100 33428    0     0   127k      0 --:--:-- --:--:-- --:--:--  127k\n"
     ]
    }
   ],
   "source": [
    "!poetry run poe download-medical-datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "seed = 1239129\n",
    "\n",
    "# Set the random seed for reproducibility\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "test_data = pd.read_csv('datasets/pima_indians_imputed.csv', index_col=0).astype(float)\n",
    "test_data[\"DiabetesPedigreeFunction\"] =  test_data[\"DiabetesPedigreeFunction\"] * 100\n",
    "test_data[\"Pregnancies\"] = test_data[\"Pregnancies\"] * 10\n",
    "\n",
    "y = test_data.iloc[:, -1]\n",
    "\n",
    "x_train, x_test = train_test_split(test_data, test_size=0.5, random_state=seed, stratify=y)\n",
    "y_train = x_train.iloc[:, -1]  # Extract labels from the training split\n",
    "x_train, x_val = train_test_split(x_train, test_size=0.1, random_state=seed, stratify=y_train)\n",
    "\n",
    "x_train.to_csv('datasets/train.csv')\n",
    "x_val.to_csv('datasets/val.csv')\n",
    "x_test.to_csv('datasets/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "def predict(model, x):\n",
    "    model.eval()  # Ensure the model is in evaluation mode\n",
    "    with torch.no_grad():  # No need to track gradients\n",
    "        # Ensure x is a tensor and has the right dtype\n",
    "        if not isinstance(x, torch.Tensor):\n",
    "            x = torch.tensor(x, dtype=torch.float32)\n",
    "        elif x.dtype != torch.float32:\n",
    "            x = x.float()\n",
    "        \n",
    "        # Forward pass through the model\n",
    "        probs = model(x)\n",
    "        \n",
    "        # Apply binary classification threshold at 0.5\n",
    "        preds = (probs > 0.5).float()\n",
    "    return preds\n",
    "\n",
    "def compute_metrics(model, data_loader):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    true_positives = 0\n",
    "    false_positives = 0\n",
    "    false_negatives = 0\n",
    "    true_negatives = 0\n",
    "    \n",
    "    all_true_labels = []\n",
    "    all_predicted_labels = []\n",
    "    \n",
    "    with torch.no_grad():  # Disable gradient computation\n",
    "        for data, labels in data_loader:\n",
    "            # Ensure data and labels are the correct dtype\n",
    "            if not isinstance(data, torch.Tensor):\n",
    "                data = torch.tensor(data, dtype=torch.float32)\n",
    "            elif data.dtype != torch.float32:\n",
    "                data = data.float()\n",
    "            \n",
    "            if not isinstance(labels, torch.Tensor):\n",
    "                labels = torch.tensor(labels, dtype=torch.float32)\n",
    "            elif labels.dtype != torch.float32:\n",
    "                labels = labels.float()\n",
    "            \n",
    "            # Get predictions\n",
    "            preds = predict(model, data)\n",
    "            \n",
    "            # Squeeze predictions and labels to remove dimensions of size 1\n",
    "            predicted_labels = preds.squeeze()\n",
    "            true_labels = labels.squeeze()\n",
    "\n",
    "            # Ensure the shapes match before comparison\n",
    "            if predicted_labels.shape != true_labels.shape:\n",
    "                true_labels = true_labels.view_as(predicted_labels)\n",
    "            \n",
    "            # Collect all predictions and true labels for MCC\n",
    "            all_true_labels.extend(true_labels.cpu().numpy())\n",
    "            all_predicted_labels.extend(predicted_labels.cpu().numpy())\n",
    "\n",
    "            # Count correct predictions\n",
    "            correct += (predicted_labels == true_labels).sum().item()\n",
    "            total += true_labels.size(0)\n",
    "            \n",
    "            # Calculate TP, FP, FN, TN\n",
    "            true_positives += ((predicted_labels == 1) & (true_labels == 1)).sum().item()\n",
    "            false_positives += ((predicted_labels == 1) & (true_labels == 0)).sum().item()\n",
    "            false_negatives += ((predicted_labels == 0) & (true_labels == 1)).sum().item()\n",
    "            true_negatives += ((predicted_labels == 0) & (true_labels == 0)).sum().item()\n",
    "    \n",
    "    accuracy = correct / total if total > 0 else 0\n",
    "    precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0\n",
    "    recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    balanced_accuracy = 0.5 * (recall + (true_negatives / (true_negatives + false_positives) if (true_negatives + false_positives) > 0 else 0))\n",
    "    mcc = matthews_corrcoef(all_true_labels, all_predicted_labels)\n",
    "    tnr = true_negatives / (true_negatives + false_positives) if (true_negatives + false_positives) > 0 else 0  # True Negative Rate\n",
    "    fpr = false_positives / (false_positives + true_negatives) if (false_positives + true_negatives) > 0 else 0  # False Positive Rate\n",
    "    fnr = false_negatives / (false_negatives + true_positives) if (false_negatives + true_positives) > 0 else 0  # False Negative Rate\n",
    "    tpr = recall  # True Positive Rate is the same as recall\n",
    "\n",
    "    print(f\"True Positives: {true_positives}, False Positives: {false_positives}, False Negatives: {false_negatives}, True Negatives: {true_negatives}, Total: {total}\")\n",
    "    print()\n",
    "    print(f\"A (Accuracy): {accuracy:.4f}\")\n",
    "    print(f\"P (Precision): {precision:.4f}\")\n",
    "    print(f\"R (Recall): {recall:.4f}\")\n",
    "    print(f\"F1 (F1 Score): {f1_score:.4f}\")\n",
    "    print(f\"BA (Balanced Accuracy): {balanced_accuracy:.4f}\")\n",
    "    print(f\"MCC (Matthews Correlation Coefficient): {mcc:.4f}\")\n",
    "    print(f\"TNR (True Negative Rate): {tnr:.4f}\")\n",
    "    print(f\"FPR (False Positive Rate): {fpr:.4f}\")\n",
    "    print(f\"FNR (False Negative Rate): {fnr:.4f}\")\n",
    "    print(f\"TPR (True Positive Rate): {tpr:.4f}\")\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "kb = KnowledgeBase(\"with_logic.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=8, out_features=256, bias=True)\n",
       "  (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): LeakyReLU(negative_slope=0.01)\n",
       "  (3): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (5): LeakyReLU(negative_slope=0.01)\n",
       "  (6): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (7): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (8): LeakyReLU(negative_slope=0.01)\n",
       "  (9): Linear(in_features=64, out_features=1, bias=True)\n",
       "  (10): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kb.predicates[\"Diabetic\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tune = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if fine_tune:\n",
    "    model = kb.predicates[\"Diabetic\"]\n",
    "\n",
    "    criteria = torch.nn.BCELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, weight_decay=0.0001)\n",
    "\n",
    "    patience = 5\n",
    "    min_delta = 0.0\n",
    "    best_val_loss = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    for epoch in range(50):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        num_batches = 0\n",
    "        \n",
    "        # Training loop\n",
    "        for data, labels in kb.loaders[0]:\n",
    "            optimizer.zero_grad()\n",
    "            predictions = model(data)\n",
    "            loss = criteria(predictions, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            num_batches += 1\n",
    "\n",
    "        avg_train_loss = total_loss / num_batches\n",
    "\n",
    "        model.eval()\n",
    "        total_val_loss = 0.0\n",
    "        num_val_batches = 0\n",
    "\n",
    "        for data, labels in kb.val_loaders[0]:\n",
    "            with torch.no_grad():\n",
    "                predictions = model(data)\n",
    "                val_loss = criteria(predictions, labels)\n",
    "                total_val_loss += val_loss.item()\n",
    "                num_val_batches += 1\n",
    "\n",
    "        avg_val_loss = total_val_loss / num_val_batches\n",
    "\n",
    "        # Early stopping logic\n",
    "        if avg_val_loss + min_delta < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(f\"Early Stopping at: Epoch {epoch + 1}, Train Loss: {avg_train_loss:.6f}, Val Loss: {avg_val_loss:.6f}\")\n",
    "            break\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"Epoch {epoch + 1}, Train Loss: {avg_train_loss:.6f}, Val Loss: {avg_val_loss:.6f}\")\n",
    "\n",
    "        model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positives: 53, False Positives: 142, False Negatives: 67, True Negatives: 83, Total: 345\n",
      "\n",
      "A (Accuracy): 0.3942\n",
      "P (Precision): 0.2718\n",
      "R (Recall): 0.4417\n",
      "F1 (F1 Score): 0.3365\n",
      "BA (Balanced Accuracy): 0.4053\n",
      "MCC (Matthews Correlation Coefficient): -0.1820\n",
      "TNR (True Negative Rate): 0.3689\n",
      "FPR (False Positive Rate): 0.6311\n",
      "FNR (False Negative Rate): 0.5583\n",
      "TPR (True Positive Rate): 0.4417\n"
     ]
    }
   ],
   "source": [
    "compute_metrics(kb.predicates[\"Diabetic\"], kb.loaders[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positives: 62, False Positives: 164, False Negatives: 72, True Negatives: 86, Total: 384\n",
      "\n",
      "A (Accuracy): 0.3854\n",
      "P (Precision): 0.2743\n",
      "R (Recall): 0.4627\n",
      "F1 (F1 Score): 0.3444\n",
      "BA (Balanced Accuracy): 0.4033\n",
      "MCC (Matthews Correlation Coefficient): -0.1872\n",
      "TNR (True Negative Rate): 0.3440\n",
      "FPR (False Positive Rate): 0.6560\n",
      "FNR (False Negative Rate): 0.5373\n",
      "TPR (True Positive Rate): 0.4627\n"
     ]
    }
   ],
   "source": [
    "compute_metrics(kb.predicates[\"Diabetic\"], kb.test_loaders[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"∀ ['person']. (((y == diabetes) -> Diabetic(person)))\", \"∀ ['person']. (((y == healthy) -> ~(Diabetic(person))))\", \"∀ ['person']. ((((person[BMI] > 29) & (person[Glucose] > 125)) -> Diabetic(person)))\", \"∀ ['person']. ((((person[BMI] < 26) & (person[Glucose] < 101)) -> ~(Diabetic(person))))\"]\n",
      "Rule Outputs:  [tensor(0.7522, grad_fn=<RsubBackward1>), tensor(0.5394, grad_fn=<RsubBackward1>), tensor(0.6810, grad_fn=<RsubBackward1>), tensor(0.7572, grad_fn=<RsubBackward1>)]\n",
      "Epoch 1/150, Train Loss: 0.3294895887374878, Validation Loss: 0.3280126452445984\n",
      "\n",
      "[\"∀ ['person']. (((y == diabetes) -> Diabetic(person)))\", \"∀ ['person']. (((y == healthy) -> ~(Diabetic(person))))\", \"∀ ['person']. ((((person[BMI] > 29) & (person[Glucose] > 125)) -> Diabetic(person)))\", \"∀ ['person']. ((((person[BMI] < 26) & (person[Glucose] < 101)) -> ~(Diabetic(person))))\"]\n",
      "Rule Outputs:  [tensor(0.8064, grad_fn=<RsubBackward1>), tensor(0.6041, grad_fn=<RsubBackward1>), tensor(0.7218, grad_fn=<RsubBackward1>), tensor(0.7949, grad_fn=<RsubBackward1>)]\n",
      "Epoch 11/150, Train Loss: 0.28004562854766846, Validation Loss: 0.2954756021499634\n",
      "\n",
      "[\"∀ ['person']. (((y == diabetes) -> Diabetic(person)))\", \"∀ ['person']. (((y == healthy) -> ~(Diabetic(person))))\", \"∀ ['person']. ((((person[BMI] > 29) & (person[Glucose] > 125)) -> Diabetic(person)))\", \"∀ ['person']. ((((person[BMI] < 26) & (person[Glucose] < 101)) -> ~(Diabetic(person))))\"]\n",
      "Rule Outputs:  [tensor(0.8395, grad_fn=<RsubBackward1>), tensor(0.6450, grad_fn=<RsubBackward1>), tensor(0.7398, grad_fn=<RsubBackward1>), tensor(0.8215, grad_fn=<RsubBackward1>)]\n",
      "Epoch 21/150, Train Loss: 0.2506673336029053, Validation Loss: 0.2723613977432251\n",
      "\n",
      "[\"∀ ['person']. (((y == diabetes) -> Diabetic(person)))\", \"∀ ['person']. (((y == healthy) -> ~(Diabetic(person))))\", \"∀ ['person']. ((((person[BMI] > 29) & (person[Glucose] > 125)) -> Diabetic(person)))\", \"∀ ['person']. ((((person[BMI] < 26) & (person[Glucose] < 101)) -> ~(Diabetic(person))))\"]\n",
      "Rule Outputs:  [tensor(0.8614, grad_fn=<RsubBackward1>), tensor(0.6734, grad_fn=<RsubBackward1>), tensor(0.7461, grad_fn=<RsubBackward1>), tensor(0.8429, grad_fn=<RsubBackward1>)]\n",
      "Epoch 31/150, Train Loss: 0.2318333387374878, Validation Loss: 0.25937867164611816\n",
      "\n",
      "[\"∀ ['person']. (((y == diabetes) -> Diabetic(person)))\", \"∀ ['person']. (((y == healthy) -> ~(Diabetic(person))))\", \"∀ ['person']. ((((person[BMI] > 29) & (person[Glucose] > 125)) -> Diabetic(person)))\", \"∀ ['person']. ((((person[BMI] < 26) & (person[Glucose] < 101)) -> ~(Diabetic(person))))\"]\n",
      "Rule Outputs:  [tensor(0.8767, grad_fn=<RsubBackward1>), tensor(0.6931, grad_fn=<RsubBackward1>), tensor(0.7515, grad_fn=<RsubBackward1>), tensor(0.8582, grad_fn=<RsubBackward1>)]\n",
      "Epoch 41/150, Train Loss: 0.2186448574066162, Validation Loss: 0.2543759346008301\n",
      "\n",
      "[\"∀ ['person']. (((y == diabetes) -> Diabetic(person)))\", \"∀ ['person']. (((y == healthy) -> ~(Diabetic(person))))\", \"∀ ['person']. ((((person[BMI] > 29) & (person[Glucose] > 125)) -> Diabetic(person)))\", \"∀ ['person']. ((((person[BMI] < 26) & (person[Glucose] < 101)) -> ~(Diabetic(person))))\"]\n",
      "Rule Outputs:  [tensor(0.8881, grad_fn=<RsubBackward1>), tensor(0.7089, grad_fn=<RsubBackward1>), tensor(0.7534, grad_fn=<RsubBackward1>), tensor(0.8658, grad_fn=<RsubBackward1>)]\n",
      "Epoch 51/150, Train Loss: 0.2097812294960022, Validation Loss: 0.2530083656311035\n",
      "\n",
      "[\"∀ ['person']. (((y == diabetes) -> Diabetic(person)))\", \"∀ ['person']. (((y == healthy) -> ~(Diabetic(person))))\", \"∀ ['person']. ((((person[BMI] > 29) & (person[Glucose] > 125)) -> Diabetic(person)))\", \"∀ ['person']. ((((person[BMI] < 26) & (person[Glucose] < 101)) -> ~(Diabetic(person))))\"]\n",
      "Rule Outputs:  [tensor(0.8961, grad_fn=<RsubBackward1>), tensor(0.7209, grad_fn=<RsubBackward1>), tensor(0.7551, grad_fn=<RsubBackward1>), tensor(0.8746, grad_fn=<RsubBackward1>)]\n",
      "Epoch 61/150, Train Loss: 0.20272183418273926, Validation Loss: 0.25183504819869995\n",
      "\n",
      "[\"∀ ['person']. (((y == diabetes) -> Diabetic(person)))\", \"∀ ['person']. (((y == healthy) -> ~(Diabetic(person))))\", \"∀ ['person']. ((((person[BMI] > 29) & (person[Glucose] > 125)) -> Diabetic(person)))\", \"∀ ['person']. ((((person[BMI] < 26) & (person[Glucose] < 101)) -> ~(Diabetic(person))))\"]\n",
      "Rule Outputs:  [tensor(0.9050, grad_fn=<RsubBackward1>), tensor(0.7296, grad_fn=<RsubBackward1>), tensor(0.7582, grad_fn=<RsubBackward1>), tensor(0.8808, grad_fn=<RsubBackward1>)]\n",
      "Epoch 71/150, Train Loss: 0.19673097133636475, Validation Loss: 0.25160229206085205\n",
      "\n",
      "[\"∀ ['person']. (((y == diabetes) -> Diabetic(person)))\", \"∀ ['person']. (((y == healthy) -> ~(Diabetic(person))))\", \"∀ ['person']. ((((person[BMI] > 29) & (person[Glucose] > 125)) -> Diabetic(person)))\", \"∀ ['person']. ((((person[BMI] < 26) & (person[Glucose] < 101)) -> ~(Diabetic(person))))\"]\n",
      "Rule Outputs:  [tensor(0.9112, grad_fn=<RsubBackward1>), tensor(0.7377, grad_fn=<RsubBackward1>), tensor(0.7603, grad_fn=<RsubBackward1>), tensor(0.8849, grad_fn=<RsubBackward1>)]\n",
      "Epoch 81/150, Train Loss: 0.191947340965271, Validation Loss: 0.25243330001831055\n",
      "\n",
      "[\"∀ ['person']. (((y == diabetes) -> Diabetic(person)))\", \"∀ ['person']. (((y == healthy) -> ~(Diabetic(person))))\", \"∀ ['person']. ((((person[BMI] > 29) & (person[Glucose] > 125)) -> Diabetic(person)))\", \"∀ ['person']. ((((person[BMI] < 26) & (person[Glucose] < 101)) -> ~(Diabetic(person))))\"]\n",
      "Rule Outputs:  [tensor(0.9159, grad_fn=<RsubBackward1>), tensor(0.7450, grad_fn=<RsubBackward1>), tensor(0.7613, grad_fn=<RsubBackward1>), tensor(0.8890, grad_fn=<RsubBackward1>)]\n",
      "Epoch 91/150, Train Loss: 0.18800663948059082, Validation Loss: 0.2533263564109802\n",
      "\n",
      "[\"∀ ['person']. (((y == diabetes) -> Diabetic(person)))\", \"∀ ['person']. (((y == healthy) -> ~(Diabetic(person))))\", \"∀ ['person']. ((((person[BMI] > 29) & (person[Glucose] > 125)) -> Diabetic(person)))\", \"∀ ['person']. ((((person[BMI] < 26) & (person[Glucose] < 101)) -> ~(Diabetic(person))))\"]\n",
      "Rule Outputs:  [tensor(0.9207, grad_fn=<RsubBackward1>), tensor(0.7513, grad_fn=<RsubBackward1>), tensor(0.7624, grad_fn=<RsubBackward1>), tensor(0.8921, grad_fn=<RsubBackward1>)]\n",
      "Epoch 101/150, Train Loss: 0.18455225229263306, Validation Loss: 0.2543916702270508\n",
      "\n",
      "[\"∀ ['person']. (((y == diabetes) -> Diabetic(person)))\", \"∀ ['person']. (((y == healthy) -> ~(Diabetic(person))))\", \"∀ ['person']. ((((person[BMI] > 29) & (person[Glucose] > 125)) -> Diabetic(person)))\", \"∀ ['person']. ((((person[BMI] < 26) & (person[Glucose] < 101)) -> ~(Diabetic(person))))\"]\n",
      "Rule Outputs:  [tensor(0.9241, grad_fn=<RsubBackward1>), tensor(0.7563, grad_fn=<RsubBackward1>), tensor(0.7633, grad_fn=<RsubBackward1>), tensor(0.8947, grad_fn=<RsubBackward1>)]\n",
      "Epoch 111/150, Train Loss: 0.18182748556137085, Validation Loss: 0.25526583194732666\n",
      "\n",
      "[\"∀ ['person']. (((y == diabetes) -> Diabetic(person)))\", \"∀ ['person']. (((y == healthy) -> ~(Diabetic(person))))\", \"∀ ['person']. ((((person[BMI] > 29) & (person[Glucose] > 125)) -> Diabetic(person)))\", \"∀ ['person']. ((((person[BMI] < 26) & (person[Glucose] < 101)) -> ~(Diabetic(person))))\"]\n",
      "Rule Outputs:  [tensor(0.9265, grad_fn=<RsubBackward1>), tensor(0.7612, grad_fn=<RsubBackward1>), tensor(0.7636, grad_fn=<RsubBackward1>), tensor(0.8971, grad_fn=<RsubBackward1>)]\n",
      "Epoch 121/150, Train Loss: 0.1795351505279541, Validation Loss: 0.2559685707092285\n",
      "\n",
      "[\"∀ ['person']. (((y == diabetes) -> Diabetic(person)))\", \"∀ ['person']. (((y == healthy) -> ~(Diabetic(person))))\", \"∀ ['person']. ((((person[BMI] > 29) & (person[Glucose] > 125)) -> Diabetic(person)))\", \"∀ ['person']. ((((person[BMI] < 26) & (person[Glucose] < 101)) -> ~(Diabetic(person))))\"]\n",
      "Rule Outputs:  [tensor(0.9283, grad_fn=<RsubBackward1>), tensor(0.7653, grad_fn=<RsubBackward1>), tensor(0.7637, grad_fn=<RsubBackward1>), tensor(0.8991, grad_fn=<RsubBackward1>)]\n",
      "Epoch 131/150, Train Loss: 0.1776362657546997, Validation Loss: 0.2562981843948364\n",
      "\n",
      "[\"∀ ['person']. (((y == diabetes) -> Diabetic(person)))\", \"∀ ['person']. (((y == healthy) -> ~(Diabetic(person))))\", \"∀ ['person']. ((((person[BMI] > 29) & (person[Glucose] > 125)) -> Diabetic(person)))\", \"∀ ['person']. ((((person[BMI] < 26) & (person[Glucose] < 101)) -> ~(Diabetic(person))))\"]\n",
      "Rule Outputs:  [tensor(0.9298, grad_fn=<RsubBackward1>), tensor(0.7687, grad_fn=<RsubBackward1>), tensor(0.7640, grad_fn=<RsubBackward1>), tensor(0.9011, grad_fn=<RsubBackward1>)]\n",
      "Epoch 141/150, Train Loss: 0.1759966015815735, Validation Loss: 0.2564636468887329\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if fine_tune:\n",
    "    kb.optimize(num_epochs=100, log_steps=10, lr=0.000001, early_stopping=True, patience=5)\n",
    "else:\n",
    "    kb.optimize(num_epochs=150, log_steps=10, lr=0.00001, early_stopping=False, patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([10.0186], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([10.0175], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([10.0165], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([10.0098], requires_grad=True)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[op.k for op in kb.converter.visitor.comparision_operators]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positives: 92, False Positives: 58, False Negatives: 28, True Negatives: 167, Total: 345\n",
      "\n",
      "A (Accuracy): 0.7507\n",
      "P (Precision): 0.6133\n",
      "R (Recall): 0.7667\n",
      "F1 (F1 Score): 0.6815\n",
      "BA (Balanced Accuracy): 0.7544\n",
      "MCC (Matthews Correlation Coefficient): 0.4889\n",
      "TNR (True Negative Rate): 0.7422\n",
      "FPR (False Positive Rate): 0.2578\n",
      "FNR (False Negative Rate): 0.2333\n",
      "TPR (True Positive Rate): 0.7667\n"
     ]
    }
   ],
   "source": [
    "compute_metrics(kb.predicates[\"Diabetic\"], kb.loaders[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positives: 96, False Positives: 89, False Negatives: 38, True Negatives: 161, Total: 384\n",
      "\n",
      "A (Accuracy): 0.6693\n",
      "P (Precision): 0.5189\n",
      "R (Recall): 0.7164\n",
      "F1 (F1 Score): 0.6019\n",
      "BA (Balanced Accuracy): 0.6802\n",
      "MCC (Matthews Correlation Coefficient): 0.3438\n",
      "TNR (True Negative Rate): 0.6440\n",
      "FPR (False Positive Rate): 0.3560\n",
      "FNR (False Negative Rate): 0.2836\n",
      "TPR (True Positive Rate): 0.7164\n"
     ]
    }
   ],
   "source": [
    "compute_metrics(kb.predicates[\"Diabetic\"], kb.test_loaders[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
