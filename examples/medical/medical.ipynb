{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ltn_imp.automation.knowledge_base import KnowledgeBase\n",
    "import torch\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37mPoe =>\u001b[0m \u001b[94mmkdir -p examples/medical/datasets\u001b[0m\n",
      "\u001b[37mPoe =>\u001b[0m \u001b[94mcurl -L -o examples/medical/datasets/pima_indians_imputed.csv https://raw.githubusercontent.com/ChristelSirocchi/hybrid-ML/main/pima_indians_imputed.csv\u001b[0m\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 33428  100 33428    0     0   285k      0 --:--:-- --:--:-- --:--:--  286k\n"
     ]
    }
   ],
   "source": [
    "!poetry run poe download-medical-datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "test_data = pd.read_csv('datasets/pima_indians_imputed.csv').astype(float)\n",
    "x_train, x_test = train_test_split(test_data, test_size=0.5, random_state=42)\n",
    "x_train.to_csv('datasets/train.csv')\n",
    "x_test.to_csv('datasets/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def predict(model, x):\n",
    "    model.eval()  # Ensure the model is in evaluation mode\n",
    "    with torch.no_grad():  # No need to track gradients\n",
    "        # Ensure x is a tensor and has the right dtype\n",
    "        if not isinstance(x, torch.Tensor):\n",
    "            x = torch.tensor(x, dtype=torch.float32)\n",
    "        elif x.dtype != torch.float32:\n",
    "            x = x.float()\n",
    "        \n",
    "        # Forward pass through the model\n",
    "        probs = model(x)\n",
    "        \n",
    "        # Apply binary classification threshold at 0.5\n",
    "        preds = (probs > 0.5).float()\n",
    "    return preds\n",
    "\n",
    "def compute_metrics(model, data_loader):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    true_positives = 0\n",
    "    false_positives = 0\n",
    "    false_negatives = 0\n",
    "    true_negatives = 0\n",
    "    \n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    with torch.no_grad():  # Disable gradient computation\n",
    "        for data, labels in data_loader:\n",
    "            # Ensure data and labels are the correct dtype\n",
    "            if not isinstance(data, torch.Tensor):\n",
    "                data = torch.tensor(data, dtype=torch.float32)\n",
    "            elif data.dtype != torch.float32:\n",
    "                data = data.float()\n",
    "            \n",
    "            if not isinstance(labels, torch.Tensor):\n",
    "                labels = torch.tensor(labels, dtype=torch.float32)\n",
    "            elif labels.dtype != torch.float32:\n",
    "                labels = labels.float()\n",
    "            \n",
    "            # Get predictions\n",
    "            preds = predict(model, data)\n",
    "            \n",
    "            # Squeeze predictions and labels to remove dimensions of size 1\n",
    "            predicted_labels = preds.squeeze()\n",
    "            true_labels = labels.squeeze()\n",
    "\n",
    "            # Ensure the shapes match before comparison\n",
    "            if predicted_labels.shape != true_labels.shape:\n",
    "                true_labels = true_labels.view_as(predicted_labels)\n",
    "            \n",
    "            # Count correct predictions\n",
    "            correct += (predicted_labels == true_labels).sum().item()\n",
    "            total += true_labels.size(0)\n",
    "            \n",
    "            # Calculate TP, FP, FN, TN\n",
    "            true_positives += ((predicted_labels == 1) & (true_labels == 1)).sum().item()\n",
    "            false_positives += ((predicted_labels == 1) & (true_labels == 0)).sum().item()\n",
    "            false_negatives += ((predicted_labels == 0) & (true_labels == 1)).sum().item()\n",
    "            true_negatives += ((predicted_labels == 0) & (true_labels == 0)).sum().item()\n",
    "    \n",
    "    accuracy = correct / total if total > 0 else 0\n",
    "    precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0\n",
    "    recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0\n",
    "    specificity = true_negatives / (true_negatives + false_positives) if (true_negatives + false_positives) > 0 else 0\n",
    "\n",
    "    print(f\"True Positives: {true_positives}, False Positives: {false_positives}, False Negatives: {false_negatives}, True Negatives: {true_negatives}\")\n",
    "    print()\n",
    "    print(f\"Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, Specificity: {specificity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "kb = KnowledgeBase(\"medical_config.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(kb.loaders[0]))\n",
    "test_data = pd.DataFrame(x)\n",
    "high = test_data[(test_data[5] > 29) & (test_data[1] > 125)]\n",
    "low = test_data[(test_data[5] <= 25) & (test_data[1] <= 100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.3745e-05, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kb.predicates[\"Classifier\"](torch.tensor(high.values, dtype=torch.float32)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0049, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kb.predicates[\"Classifier\"](torch.tensor(low.values, dtype=torch.float32)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positives: 0, False Positives: 0, False Negatives: 138, True Negatives: 246\n",
      "\n",
      "Accuracy: 0.6406, Precision: 0.0000, Recall: 0.0000, Specificity: 1.0000\n"
     ]
    }
   ],
   "source": [
    "compute_metrics(kb.predicates[\"Classifier\"], kb.loaders[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positives: 0, False Positives: 0, False Negatives: 130, True Negatives: 254\n",
      "\n",
      "Accuracy: 0.6615, Precision: 0.0000, Recall: 0.0000, Specificity: 1.0000\n"
     ]
    }
   ],
   "source": [
    "compute_metrics(kb.predicates[\"Classifier\"], kb.loaders[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['∀ person.(((y == diabetes) -> Classifier(person)))', '∀ person.(((y == healthy) -> ~(Classifier(person))))', '∀ person.((((person[BMI] < 26) & (person[Glucose] < 101)) -> ~(Classifier(person))))', '∀ person.((((person[BMI] > 29) & (person[Glucose] > 125)) -> Classifier(person)))']\n",
      "Rule Outputs:  [tensor(0.5984, grad_fn=<RsubBackward1>), tensor(0.5713, grad_fn=<RsubBackward1>), tensor(0.8401, grad_fn=<RsubBackward1>), tensor(0.6764, grad_fn=<RsubBackward1>)]\n",
      "Epoch 1/1001, Loss: 0.3447195291519165\n",
      "\n",
      "['∀ person.(((y == diabetes) -> Classifier(person)))', '∀ person.(((y == healthy) -> ~(Classifier(person))))', '∀ person.((((person[BMI] < 26) & (person[Glucose] < 101)) -> ~(Classifier(person))))', '∀ person.((((person[BMI] > 29) & (person[Glucose] > 125)) -> Classifier(person)))']\n",
      "Rule Outputs:  [tensor(0.9441, grad_fn=<RsubBackward1>), tensor(0.8684, grad_fn=<RsubBackward1>), tensor(0.9994, grad_fn=<RsubBackward1>), tensor(0.8725, grad_fn=<RsubBackward1>)]\n",
      "Epoch 501/1001, Loss: 0.0957866907119751\n",
      "\n",
      "['∀ person.(((y == diabetes) -> Classifier(person)))', '∀ person.(((y == healthy) -> ~(Classifier(person))))', '∀ person.((((person[BMI] < 26) & (person[Glucose] < 101)) -> ~(Classifier(person))))', '∀ person.((((person[BMI] > 29) & (person[Glucose] > 125)) -> Classifier(person)))']\n",
      "Rule Outputs:  [tensor(0.9441, grad_fn=<RsubBackward1>), tensor(0.8627, grad_fn=<RsubBackward1>), tensor(0.9996, grad_fn=<RsubBackward1>), tensor(0.8784, grad_fn=<RsubBackward1>)]\n",
      "Epoch 1001/1001, Loss: 0.09584641456604004\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kb.optimize(num_epochs=1001, log_steps=500, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positives: 93, False Positives: 72, False Negatives: 45, True Negatives: 174\n",
      "\n",
      "Accuracy: 0.6953, Precision: 0.5636, Recall: 0.6739, Specificity: 0.7073\n"
     ]
    }
   ],
   "source": [
    "compute_metrics(kb.predicates[\"Classifier\"], kb.loaders[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positives: 86, False Positives: 87, False Negatives: 44, True Negatives: 167\n",
      "\n",
      "Accuracy: 0.6589, Precision: 0.4971, Recall: 0.6615, Specificity: 0.6575\n"
     ]
    }
   ],
   "source": [
    "compute_metrics(kb.predicates[\"Classifier\"], kb.loaders[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8670, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kb.predicates[\"Classifier\"](torch.tensor(high.values, dtype=torch.float32)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1., grad_fn=<RoundBackward0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kb.predicates[\"Classifier\"](torch.tensor(low.values, dtype=torch.float32)).mean().round()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
