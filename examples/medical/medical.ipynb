{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ltn_imp.automation.knowledge_base import KnowledgeBase\n",
    "import torch\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37mPoe =>\u001b[0m \u001b[94mmkdir -p examples/medical/datasets\u001b[0m\n",
      "\u001b[37mPoe =>\u001b[0m \u001b[94mcurl -L -o examples/medical/datasets/pima_indians_imputed.csv https://raw.githubusercontent.com/ChristelSirocchi/hybrid-ML/main/pima_indians_imputed.csv\u001b[0m\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 33428  100 33428    0     0   309k      0 --:--:-- --:--:-- --:--:--  310k\n"
     ]
    }
   ],
   "source": [
    "!poetry run poe download-medical-datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(\"datasets/pima_indians_imputed.csv\", index_col=0).astype(float).to_csv(\"datasets/pima_indians_imputed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, x):\n",
    "    model.eval()  # Ensure the model is in evaluation mode\n",
    "    with torch.no_grad():  # No need to track gradients\n",
    "        # Ensure x is a tensor and has the right dtype\n",
    "        if not isinstance(x, torch.Tensor):\n",
    "            x = torch.tensor(x, dtype=torch.float32)\n",
    "        elif x.dtype != torch.float32:\n",
    "            x = x.float()\n",
    "        \n",
    "        # Forward pass through the model\n",
    "        probs = model(x)\n",
    "        \n",
    "        # Apply binary classification threshold at 0.5\n",
    "        preds = (probs > 0.5).float()\n",
    "    return preds\n",
    "\n",
    "def compute_accuracy(model, data_loader):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    with torch.no_grad():  # Disable gradient computation\n",
    "        for data, labels in data_loader:\n",
    "            # Ensure data and labels are the correct dtype\n",
    "            if not isinstance(data, torch.Tensor):\n",
    "                data = torch.tensor(data, dtype=torch.float32)\n",
    "            elif data.dtype != torch.float32:\n",
    "                data = data.float()\n",
    "            \n",
    "            if not isinstance(labels, torch.Tensor):\n",
    "                labels = torch.tensor(labels, dtype=torch.float32)\n",
    "            elif labels.dtype != torch.float32:\n",
    "                labels = labels.float()\n",
    "            \n",
    "            # Get predictions\n",
    "            preds = predict(model, data)\n",
    "            \n",
    "            # Squeeze predictions and labels to remove dimensions of size 1\n",
    "            predicted_labels = preds.squeeze()\n",
    "            true_labels = labels.squeeze()\n",
    "\n",
    "            # Ensure the shapes match before comparison\n",
    "            if predicted_labels.shape != true_labels.shape:\n",
    "                true_labels = true_labels.view_as(predicted_labels)\n",
    "            \n",
    "            # Count correct predictions\n",
    "            correct += (predicted_labels == true_labels).sum().item()\n",
    "            total += true_labels.size(0)\n",
    "\n",
    "    accuracy = correct / total if total > 0 else 0\n",
    "    print(f\"Correct: {correct}, Total: {total}, Accuracy: {accuracy:.4f}\")\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "kb = KnowledgeBase(\"medical_config.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct: 268, Total: 768, Accuracy: 0.3490\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3489583333333333"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_accuracy(kb.predicates[\"Classifier\"], kb.loaders[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['∀ person.(((y == diabetes) -> Classifier(person)))', '∀ person.(((y == healthy) -> ~(Classifier(person))))']\n",
      "Rule Outputs:  [tensor(0.3277, grad_fn=<RsubBackward1>), tensor(0.8468, grad_fn=<RsubBackward1>)]\n",
      "Epoch 1/501, Loss: 0.4875742197036743\n",
      "\n",
      "['∀ person.(((y == diabetes) -> Classifier(person)))', '∀ person.(((y == healthy) -> ~(Classifier(person))))']\n",
      "Rule Outputs:  [tensor(0.5875, grad_fn=<RsubBackward1>), tensor(0.6722, grad_fn=<RsubBackward1>)]\n",
      "Epoch 101/501, Loss: 0.3725748658180237\n",
      "\n",
      "['∀ person.(((y == diabetes) -> Classifier(person)))', '∀ person.(((y == healthy) -> ~(Classifier(person))))']\n",
      "Rule Outputs:  [tensor(0.6274, grad_fn=<RsubBackward1>), tensor(0.6935, grad_fn=<RsubBackward1>)]\n",
      "Epoch 201/501, Loss: 0.34117352962493896\n",
      "\n",
      "['∀ person.(((y == diabetes) -> Classifier(person)))', '∀ person.(((y == healthy) -> ~(Classifier(person))))']\n",
      "Rule Outputs:  [tensor(0.6419, grad_fn=<RsubBackward1>), tensor(0.7084, grad_fn=<RsubBackward1>)]\n",
      "Epoch 301/501, Loss: 0.32653164863586426\n",
      "\n",
      "['∀ person.(((y == diabetes) -> Classifier(person)))', '∀ person.(((y == healthy) -> ~(Classifier(person))))']\n",
      "Rule Outputs:  [tensor(0.6509, grad_fn=<RsubBackward1>), tensor(0.7102, grad_fn=<RsubBackward1>)]\n",
      "Epoch 401/501, Loss: 0.3208073377609253\n",
      "\n",
      "['∀ person.(((y == diabetes) -> Classifier(person)))', '∀ person.(((y == healthy) -> ~(Classifier(person))))']\n",
      "Rule Outputs:  [tensor(0.6529, grad_fn=<RsubBackward1>), tensor(0.7150, grad_fn=<RsubBackward1>)]\n",
      "Epoch 501/501, Loss: 0.31759095191955566\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kb.optimize(num_epochs=501, log_steps=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct: 548, Total: 768, Accuracy: 0.7135\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7135416666666666"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_accuracy(kb.predicates[\"Classifier\"], kb.loaders[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
