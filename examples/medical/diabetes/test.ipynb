{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ltn_imp.automation.knowledge_base import KnowledgeBase\n",
    "import torch\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37mPoe =>\u001b[0m \u001b[94mmkdir -p examples/medical/datasets\u001b[0m\n",
      "\u001b[37mPoe =>\u001b[0m \u001b[94mcurl -L -o examples/medical/datasets/pima_indians_imputed.csv https://raw.githubusercontent.com/ChristelSirocchi/hybrid-ML/main/pima_indians_imputed.csv\u001b[0m\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 33428  100 33428    0     0   449k      0 --:--:-- --:--:-- --:--:--  453k\n"
     ]
    }
   ],
   "source": [
    "!poetry run poe download-medical-datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "seed = 1239129\n",
    "\n",
    "# Set the random seed for reproducibility\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "test_data = pd.read_csv('datasets/pima_indians_imputed.csv', index_col=0).astype(float)\n",
    "\n",
    "y = test_data.iloc[:, -1]\n",
    "\n",
    "x_train, x_test = train_test_split(test_data, test_size=0.5, random_state=seed, stratify=y)\n",
    "y_train = x_train.iloc[:, -1]  # Extract labels from the training split\n",
    "x_train, x_val = train_test_split(x_train, test_size=0.1, random_state=seed, stratify=y_train)\n",
    "\n",
    "x_train.to_csv('datasets/train.csv')\n",
    "x_val.to_csv('datasets/val.csv')\n",
    "x_test.to_csv('datasets/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "def predict(model, x):\n",
    "    model.eval()  # Ensure the model is in evaluation mode\n",
    "    with torch.no_grad():  # No need to track gradients\n",
    "        # Ensure x is a tensor and has the right dtype\n",
    "        if not isinstance(x, torch.Tensor):\n",
    "            x = torch.tensor(x, dtype=torch.float32)\n",
    "        elif x.dtype != torch.float32:\n",
    "            x = x.float()\n",
    "        \n",
    "        # Forward pass through the model\n",
    "        probs = model(x)\n",
    "        \n",
    "        # Apply binary classification threshold at 0.5\n",
    "        preds = (probs > 0.5).float()\n",
    "    return preds\n",
    "\n",
    "def compute_metrics(model, data_loader):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    true_positives = 0\n",
    "    false_positives = 0\n",
    "    false_negatives = 0\n",
    "    true_negatives = 0\n",
    "    \n",
    "    all_true_labels = []\n",
    "    all_predicted_labels = []\n",
    "    \n",
    "    with torch.no_grad():  # Disable gradient computation\n",
    "        for data, labels in data_loader:\n",
    "            # Ensure data and labels are the correct dtype\n",
    "            if not isinstance(data, torch.Tensor):\n",
    "                data = torch.tensor(data, dtype=torch.float32)\n",
    "            elif data.dtype != torch.float32:\n",
    "                data = data.float()\n",
    "            \n",
    "            if not isinstance(labels, torch.Tensor):\n",
    "                labels = torch.tensor(labels, dtype=torch.float32)\n",
    "            elif labels.dtype != torch.float32:\n",
    "                labels = labels.float()\n",
    "            \n",
    "            # Get predictions\n",
    "            preds = predict(model, data)\n",
    "            \n",
    "            # Squeeze predictions and labels to remove dimensions of size 1\n",
    "            predicted_labels = preds.squeeze()\n",
    "            true_labels = labels.squeeze()\n",
    "\n",
    "            # Ensure the shapes match before comparison\n",
    "            if predicted_labels.shape != true_labels.shape:\n",
    "                true_labels = true_labels.view_as(predicted_labels)\n",
    "            \n",
    "            # Collect all predictions and true labels for MCC\n",
    "            all_true_labels.extend(true_labels.cpu().numpy())\n",
    "            all_predicted_labels.extend(predicted_labels.cpu().numpy())\n",
    "\n",
    "            # Count correct predictions\n",
    "            correct += (predicted_labels == true_labels).sum().item()\n",
    "            total += true_labels.size(0)\n",
    "            \n",
    "            # Calculate TP, FP, FN, TN\n",
    "            true_positives += ((predicted_labels == 1) & (true_labels == 1)).sum().item()\n",
    "            false_positives += ((predicted_labels == 1) & (true_labels == 0)).sum().item()\n",
    "            false_negatives += ((predicted_labels == 0) & (true_labels == 1)).sum().item()\n",
    "            true_negatives += ((predicted_labels == 0) & (true_labels == 0)).sum().item()\n",
    "    \n",
    "    accuracy = correct / total if total > 0 else 0\n",
    "    precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0\n",
    "    recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    balanced_accuracy = 0.5 * (recall + (true_negatives / (true_negatives + false_positives) if (true_negatives + false_positives) > 0 else 0))\n",
    "    mcc = matthews_corrcoef(all_true_labels, all_predicted_labels)\n",
    "    tnr = true_negatives / (true_negatives + false_positives) if (true_negatives + false_positives) > 0 else 0  # True Negative Rate\n",
    "    fpr = false_positives / (false_positives + true_negatives) if (false_positives + true_negatives) > 0 else 0  # False Positive Rate\n",
    "    fnr = false_negatives / (false_negatives + true_positives) if (false_negatives + true_positives) > 0 else 0  # False Negative Rate\n",
    "    tpr = recall  # True Positive Rate is the same as recall\n",
    "\n",
    "    print(f\"True Positives: {true_positives}, False Positives: {false_positives}, False Negatives: {false_negatives}, True Negatives: {true_negatives}, Total: {total}\")\n",
    "    print()\n",
    "    print(f\"A (Accuracy): {accuracy:.4f}\")\n",
    "    print(f\"P (Precision): {precision:.4f}\")\n",
    "    print(f\"R (Recall): {recall:.4f}\")\n",
    "    print(f\"F1 (F1 Score): {f1_score:.4f}\")\n",
    "    print(f\"BA (Balanced Accuracy): {balanced_accuracy:.4f}\")\n",
    "    print(f\"MCC (Matthews Correlation Coefficient): {mcc:.4f}\")\n",
    "    print(f\"TNR (True Negative Rate): {tnr:.4f}\")\n",
    "    print(f\"FPR (False Positive Rate): {fpr:.4f}\")\n",
    "    print(f\"FNR (False Negative Rate): {fnr:.4f}\")\n",
    "    print(f\"TPR (True Positive Rate): {tpr:.4f}\")\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "kb = KnowledgeBase(\"with_logic.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<LogicTensorNetwork: ['person']>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kb.predicates[\"Diabetic\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tune = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 0.667559, Val Loss: 0.666479\n",
      "Epoch 11, Train Loss: 0.422746, Val Loss: 0.511885\n",
      "Epoch 21, Train Loss: 0.343546, Val Loss: 0.497202\n",
      "Early Stopping at: Epoch 28, Train Loss: 0.324318, Val Loss: 0.502187\n"
     ]
    }
   ],
   "source": [
    "if fine_tune:\n",
    "    model = kb.predicates[\"Diabetic\"]\n",
    "\n",
    "    criteria = torch.nn.BCELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, weight_decay=0.0001)\n",
    "\n",
    "    patience = 5\n",
    "    min_delta = 0.0\n",
    "    best_val_loss = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    for epoch in range(50):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        num_batches = 0\n",
    "        \n",
    "        # Training loop\n",
    "        for data, labels in kb.loaders[0]:\n",
    "            optimizer.zero_grad()\n",
    "            predictions = model(data)\n",
    "            loss = criteria(predictions, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            num_batches += 1\n",
    "\n",
    "        avg_train_loss = total_loss / num_batches\n",
    "\n",
    "        model.eval()\n",
    "        total_val_loss = 0.0\n",
    "        num_val_batches = 0\n",
    "\n",
    "        for data, labels in kb.val_loaders[0]:\n",
    "            with torch.no_grad():\n",
    "                predictions = model(data)\n",
    "                val_loss = criteria(predictions, labels)\n",
    "                total_val_loss += val_loss.item()\n",
    "                num_val_batches += 1\n",
    "\n",
    "        avg_val_loss = total_val_loss / num_val_batches\n",
    "\n",
    "        # Early stopping logic\n",
    "        if avg_val_loss + min_delta < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(f\"Early Stopping at: Epoch {epoch + 1}, Train Loss: {avg_train_loss:.6f}, Val Loss: {avg_val_loss:.6f}\")\n",
    "            break\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"Epoch {epoch + 1}, Train Loss: {avg_train_loss:.6f}, Val Loss: {avg_val_loss:.6f}\")\n",
    "\n",
    "        model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positives: 97, False Positives: 9, False Negatives: 23, True Negatives: 216, Total: 345\n",
      "\n",
      "A (Accuracy): 0.9072\n",
      "P (Precision): 0.9151\n",
      "R (Recall): 0.8083\n",
      "F1 (F1 Score): 0.8584\n",
      "BA (Balanced Accuracy): 0.8842\n",
      "MCC (Matthews Correlation Coefficient): 0.7932\n",
      "TNR (True Negative Rate): 0.9600\n",
      "FPR (False Positive Rate): 0.0400\n",
      "FNR (False Negative Rate): 0.1917\n",
      "TPR (True Positive Rate): 0.8083\n"
     ]
    }
   ],
   "source": [
    "compute_metrics(kb.predicates[\"Diabetic\"], kb.loaders[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positives: 81, False Positives: 35, False Negatives: 53, True Negatives: 215, Total: 384\n",
      "\n",
      "A (Accuracy): 0.7708\n",
      "P (Precision): 0.6983\n",
      "R (Recall): 0.6045\n",
      "F1 (F1 Score): 0.6480\n",
      "BA (Balanced Accuracy): 0.7322\n",
      "MCC (Matthews Correlation Coefficient): 0.4822\n",
      "TNR (True Negative Rate): 0.8600\n",
      "FPR (False Positive Rate): 0.1400\n",
      "FNR (False Negative Rate): 0.3955\n",
      "TPR (True Positive Rate): 0.6045\n"
     ]
    }
   ],
   "source": [
    "compute_metrics(kb.predicates[\"Diabetic\"], kb.test_loaders[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor1:  tensor([23.1624, 41.5962, 30.5168, 36.9161, 22.2073, 39.1129, 32.0450, 44.0795,\n",
      "        28.2245, 30.8988, 32.4270, 32.0450, 44.7481, 29.7527, 21.6342, 32.9046,\n",
      "        32.8091, 34.5283, 39.1129, 37.2026, 31.2809, 27.7470, 35.8655, 39.4949,\n",
      "        34.3373, 36.1520, 49.2371, 33.8597, 40.9276, 20.1060, 31.6629, 24.7861])\n",
      "Tensor2:  tensor(26., requires_grad=True)\n",
      "Tensor1 Normalized:  tensor([0.1049, 0.7377, 0.3574, 0.5770, 0.0721, 0.6525, 0.4098, 0.8230, 0.2787,\n",
      "        0.3705, 0.4230, 0.4098, 0.8459, 0.3311, 0.0525, 0.4393, 0.4361, 0.4951,\n",
      "        0.6525, 0.5869, 0.3836, 0.2623, 0.5410, 0.6656, 0.4885, 0.5508, 1.0000,\n",
      "        0.4721, 0.7148, 0.0000, 0.3967, 0.1607], grad_fn=<DivBackward0>)\n",
      "Tensor2 Normalized:  tensor([0.2023], grad_fn=<DivBackward0>)\n",
      "Result:  tensor([0.6642, 0.0230, 0.2525, 0.0677, 0.7133, 0.0411, 0.1896, 0.0128, 0.3695,\n",
      "        0.2356, 0.1759, 0.1896, 0.0109, 0.2887, 0.7406, 0.1599, 0.1630, 0.1141,\n",
      "        0.0411, 0.0635, 0.2194, 0.3966, 0.0854, 0.0376, 0.1188, 0.0802, 0.0037,\n",
      "        0.1314, 0.0269, 0.8048, 0.2041, 0.5724], grad_fn=<SigmoidBackward0>)\n",
      "Tensor1:  tensor([107.2772, 183.0022,  84.7644, 112.3937,  57.1350, 159.4660, 146.1630,\n",
      "         96.0208, 148.2096, 108.3005, 134.9066, 101.1373, 120.5802, 121.6035,\n",
      "         97.0441, 134.9066, 166.6292,  87.8343, 149.2329, 142.0697, 107.2772,\n",
      "        112.3937, 110.3471,  80.6711, 113.4171, 128.7667, 154.3495, 190.1653,\n",
      "         86.8110,  92.9509,  94.9975,  85.7877])\n",
      "Tensor2:  tensor(101., requires_grad=True)\n",
      "Tensor1 Normalized:  tensor([0.3769, 0.9462, 0.2077, 0.4154, 0.0000, 0.7692, 0.6692, 0.2923, 0.6846,\n",
      "        0.3846, 0.5846, 0.3308, 0.4769, 0.4846, 0.3000, 0.5846, 0.8231, 0.2308,\n",
      "        0.6923, 0.6385, 0.3769, 0.4154, 0.4000, 0.1769, 0.4231, 0.5385, 0.7308,\n",
      "        1.0000, 0.2231, 0.2692, 0.2846, 0.2154], grad_fn=<DivBackward0>)\n",
      "Tensor2 Normalized:  tensor([0.3297], grad_fn=<DivBackward0>)\n",
      "Result:  tensor([0.4182, 0.0132, 0.7015, 0.3545, 0.9096, 0.0441, 0.0850, 0.5651, 0.0770,\n",
      "        0.4051, 0.1438, 0.4982, 0.2630, 0.2527, 0.5519, 0.1438, 0.0307, 0.6666,\n",
      "        0.0732, 0.1033, 0.4182, 0.3545, 0.3795, 0.7445, 0.3422, 0.1883, 0.0569,\n",
      "        0.0091, 0.6784, 0.6043, 0.5783, 0.6901], grad_fn=<SigmoidBackward0>)\n",
      "Tensor1:  tensor([23.1624, 41.5962, 30.5168, 36.9161, 22.2073, 39.1129, 32.0450, 44.0795,\n",
      "        28.2245, 30.8988, 32.4270, 32.0450, 44.7481, 29.7527, 21.6342, 32.9046,\n",
      "        32.8091, 34.5283, 39.1129, 37.2026, 31.2809, 27.7470, 35.8655, 39.4949,\n",
      "        34.3373, 36.1520, 49.2371, 33.8597, 40.9276, 20.1060, 31.6629, 24.7861])\n",
      "Tensor2:  tensor(26., requires_grad=True)\n",
      "Tensor1 Normalized:  tensor([0.1049, 0.7377, 0.3574, 0.5770, 0.0721, 0.6525, 0.4098, 0.8230, 0.2787,\n",
      "        0.3705, 0.4230, 0.4098, 0.8459, 0.3311, 0.0525, 0.4393, 0.4361, 0.4951,\n",
      "        0.6525, 0.5869, 0.3836, 0.2623, 0.5410, 0.6656, 0.4885, 0.5508, 1.0000,\n",
      "        0.4721, 0.7148, 0.0000, 0.3967, 0.1607], grad_fn=<DivBackward0>)\n",
      "Tensor2 Normalized:  tensor([0.2023], grad_fn=<DivBackward0>)\n",
      "Result:  tensor([0.6642, 0.0230, 0.2525, 0.0677, 0.7133, 0.0411, 0.1896, 0.0128, 0.3695,\n",
      "        0.2356, 0.1759, 0.1896, 0.0109, 0.2887, 0.7406, 0.1599, 0.1630, 0.1141,\n",
      "        0.0411, 0.0635, 0.2194, 0.3966, 0.0854, 0.0376, 0.1188, 0.0802, 0.0037,\n",
      "        0.1314, 0.0269, 0.8048, 0.2041, 0.5724], grad_fn=<SigmoidBackward0>)\n",
      "Tensor1:  tensor([107.2772, 183.0022,  84.7644, 112.3937,  57.1350, 159.4660, 146.1630,\n",
      "         96.0208, 148.2096, 108.3005, 134.9066, 101.1373, 120.5802, 121.6035,\n",
      "         97.0441, 134.9066, 166.6292,  87.8343, 149.2329, 142.0697, 107.2772,\n",
      "        112.3937, 110.3471,  80.6711, 113.4171, 128.7667, 154.3495, 190.1653,\n",
      "         86.8110,  92.9509,  94.9975,  85.7877])\n",
      "Tensor2:  tensor(101., requires_grad=True)\n",
      "Tensor1 Normalized:  tensor([0.3769, 0.9462, 0.2077, 0.4154, 0.0000, 0.7692, 0.6692, 0.2923, 0.6846,\n",
      "        0.3846, 0.5846, 0.3308, 0.4769, 0.4846, 0.3000, 0.5846, 0.8231, 0.2308,\n",
      "        0.6923, 0.6385, 0.3769, 0.4154, 0.4000, 0.1769, 0.4231, 0.5385, 0.7308,\n",
      "        1.0000, 0.2231, 0.2692, 0.2846, 0.2154], grad_fn=<DivBackward0>)\n",
      "Tensor2 Normalized:  tensor([0.3297], grad_fn=<DivBackward0>)\n",
      "Result:  tensor([0.4182, 0.0132, 0.7015, 0.3545, 0.9096, 0.0441, 0.0850, 0.5651, 0.0770,\n",
      "        0.4051, 0.1438, 0.4982, 0.2630, 0.2527, 0.5519, 0.1438, 0.0307, 0.6666,\n",
      "        0.0732, 0.1033, 0.4182, 0.3545, 0.3795, 0.7445, 0.3422, 0.1883, 0.0569,\n",
      "        0.0091, 0.6784, 0.6043, 0.5783, 0.6901], grad_fn=<SigmoidBackward0>)\n",
      "Tensor1:  tensor([23.1624, 41.5962, 30.5168, 36.9161, 22.2073, 39.1129, 32.0450, 44.0795,\n",
      "        28.2245, 30.8988, 32.4270, 32.0450, 44.7481, 29.7527, 21.6342, 32.9046,\n",
      "        32.8091, 34.5283, 39.1129, 37.2026, 31.2809, 27.7470, 35.8655, 39.4949,\n",
      "        34.3373, 36.1520, 49.2371, 33.8597, 40.9276, 20.1060, 31.6629, 24.7861])\n",
      "Tensor2:  tensor(26., requires_grad=True)\n",
      "Tensor1 Normalized:  tensor([0.1049, 0.7377, 0.3574, 0.5770, 0.0721, 0.6525, 0.4098, 0.8230, 0.2787,\n",
      "        0.3705, 0.4230, 0.4098, 0.8459, 0.3311, 0.0525, 0.4393, 0.4361, 0.4951,\n",
      "        0.6525, 0.5869, 0.3836, 0.2623, 0.5410, 0.6656, 0.4885, 0.5508, 1.0000,\n",
      "        0.4721, 0.7148, 0.0000, 0.3967, 0.1607], grad_fn=<DivBackward0>)\n",
      "Tensor2 Normalized:  tensor([0.2023], grad_fn=<DivBackward0>)\n",
      "Result:  tensor([0.6642, 0.0230, 0.2525, 0.0677, 0.7133, 0.0411, 0.1896, 0.0128, 0.3695,\n",
      "        0.2356, 0.1759, 0.1896, 0.0109, 0.2887, 0.7406, 0.1599, 0.1630, 0.1141,\n",
      "        0.0411, 0.0635, 0.2194, 0.3966, 0.0854, 0.0376, 0.1188, 0.0802, 0.0037,\n",
      "        0.1314, 0.0269, 0.8048, 0.2041, 0.5724], grad_fn=<SigmoidBackward0>)\n",
      "Tensor1:  tensor([107.2772, 183.0022,  84.7644, 112.3937,  57.1350, 159.4660, 146.1630,\n",
      "         96.0208, 148.2096, 108.3005, 134.9066, 101.1373, 120.5802, 121.6035,\n",
      "         97.0441, 134.9066, 166.6292,  87.8343, 149.2329, 142.0697, 107.2772,\n",
      "        112.3937, 110.3471,  80.6711, 113.4171, 128.7667, 154.3495, 190.1653,\n",
      "         86.8110,  92.9509,  94.9975,  85.7877])\n",
      "Tensor2:  tensor(101., requires_grad=True)\n",
      "Tensor1 Normalized:  tensor([0.3769, 0.9462, 0.2077, 0.4154, 0.0000, 0.7692, 0.6692, 0.2923, 0.6846,\n",
      "        0.3846, 0.5846, 0.3308, 0.4769, 0.4846, 0.3000, 0.5846, 0.8231, 0.2308,\n",
      "        0.6923, 0.6385, 0.3769, 0.4154, 0.4000, 0.1769, 0.4231, 0.5385, 0.7308,\n",
      "        1.0000, 0.2231, 0.2692, 0.2846, 0.2154], grad_fn=<DivBackward0>)\n",
      "Tensor2 Normalized:  tensor([0.3297], grad_fn=<DivBackward0>)\n",
      "Result:  tensor([0.4182, 0.0132, 0.7015, 0.3545, 0.9096, 0.0441, 0.0850, 0.5651, 0.0770,\n",
      "        0.4051, 0.1438, 0.4982, 0.2630, 0.2527, 0.5519, 0.1438, 0.0307, 0.6666,\n",
      "        0.0732, 0.1033, 0.4182, 0.3545, 0.3795, 0.7445, 0.3422, 0.1883, 0.0569,\n",
      "        0.0091, 0.6784, 0.6043, 0.5783, 0.6901], grad_fn=<SigmoidBackward0>)\n",
      "Tensor1:  tensor([23.1624, 41.5962, 30.5168, 36.9161, 22.2073, 39.1129, 32.0450, 44.0795,\n",
      "        28.2245, 30.8988, 32.4270, 32.0450, 44.7481, 29.7527, 21.6342, 32.9046,\n",
      "        32.8091, 34.5283, 39.1129, 37.2026, 31.2809, 27.7470, 35.8655, 39.4949,\n",
      "        34.3373, 36.1520, 49.2371, 33.8597, 40.9276, 20.1060, 31.6629, 24.7861])\n",
      "Tensor2:  tensor(26., requires_grad=True)\n",
      "Tensor1 Normalized:  tensor([0.1049, 0.7377, 0.3574, 0.5770, 0.0721, 0.6525, 0.4098, 0.8230, 0.2787,\n",
      "        0.3705, 0.4230, 0.4098, 0.8459, 0.3311, 0.0525, 0.4393, 0.4361, 0.4951,\n",
      "        0.6525, 0.5869, 0.3836, 0.2623, 0.5410, 0.6656, 0.4885, 0.5508, 1.0000,\n",
      "        0.4721, 0.7148, 0.0000, 0.3967, 0.1607], grad_fn=<DivBackward0>)\n",
      "Tensor2 Normalized:  tensor([0.2023], grad_fn=<DivBackward0>)\n",
      "Result:  tensor([0.6642, 0.0230, 0.2525, 0.0677, 0.7133, 0.0411, 0.1896, 0.0128, 0.3695,\n",
      "        0.2356, 0.1759, 0.1896, 0.0109, 0.2887, 0.7406, 0.1599, 0.1630, 0.1141,\n",
      "        0.0411, 0.0635, 0.2194, 0.3966, 0.0854, 0.0376, 0.1188, 0.0802, 0.0037,\n",
      "        0.1314, 0.0269, 0.8048, 0.2041, 0.5724], grad_fn=<SigmoidBackward0>)\n",
      "Tensor1:  tensor([107.2772, 183.0022,  84.7644, 112.3937,  57.1350, 159.4660, 146.1630,\n",
      "         96.0208, 148.2096, 108.3005, 134.9066, 101.1373, 120.5802, 121.6035,\n",
      "         97.0441, 134.9066, 166.6292,  87.8343, 149.2329, 142.0697, 107.2772,\n",
      "        112.3937, 110.3471,  80.6711, 113.4171, 128.7667, 154.3495, 190.1653,\n",
      "         86.8110,  92.9509,  94.9975,  85.7877])\n",
      "Tensor2:  tensor(101., requires_grad=True)\n",
      "Tensor1 Normalized:  tensor([0.3769, 0.9462, 0.2077, 0.4154, 0.0000, 0.7692, 0.6692, 0.2923, 0.6846,\n",
      "        0.3846, 0.5846, 0.3308, 0.4769, 0.4846, 0.3000, 0.5846, 0.8231, 0.2308,\n",
      "        0.6923, 0.6385, 0.3769, 0.4154, 0.4000, 0.1769, 0.4231, 0.5385, 0.7308,\n",
      "        1.0000, 0.2231, 0.2692, 0.2846, 0.2154], grad_fn=<DivBackward0>)\n",
      "Tensor2 Normalized:  tensor([0.3297], grad_fn=<DivBackward0>)\n",
      "Result:  tensor([0.4182, 0.0132, 0.7015, 0.3545, 0.9096, 0.0441, 0.0850, 0.5651, 0.0770,\n",
      "        0.4051, 0.1438, 0.4982, 0.2630, 0.2527, 0.5519, 0.1438, 0.0307, 0.6666,\n",
      "        0.0732, 0.1033, 0.4182, 0.3545, 0.3795, 0.7445, 0.3422, 0.1883, 0.0569,\n",
      "        0.0091, 0.6784, 0.6043, 0.5783, 0.6901], grad_fn=<SigmoidBackward0>)\n",
      "Tensor1:  tensor([23.1624, 41.5962, 30.5168, 36.9161, 22.2073, 39.1129, 32.0450, 44.0795,\n",
      "        28.2245, 30.8988, 32.4270, 32.0450, 44.7481, 29.7527, 21.6342, 32.9046,\n",
      "        32.8091, 34.5283, 39.1129, 37.2026, 31.2809, 27.7470, 35.8655, 39.4949,\n",
      "        34.3373, 36.1520, 49.2371, 33.8597, 40.9276, 20.1060, 31.6629, 24.7861])\n",
      "Tensor2:  tensor(26., requires_grad=True)\n",
      "Tensor1 Normalized:  tensor([0.1049, 0.7377, 0.3574, 0.5770, 0.0721, 0.6525, 0.4098, 0.8230, 0.2787,\n",
      "        0.3705, 0.4230, 0.4098, 0.8459, 0.3311, 0.0525, 0.4393, 0.4361, 0.4951,\n",
      "        0.6525, 0.5869, 0.3836, 0.2623, 0.5410, 0.6656, 0.4885, 0.5508, 1.0000,\n",
      "        0.4721, 0.7148, 0.0000, 0.3967, 0.1607], grad_fn=<DivBackward0>)\n",
      "Tensor2 Normalized:  tensor([0.2023], grad_fn=<DivBackward0>)\n",
      "Result:  tensor([0.6642, 0.0230, 0.2525, 0.0677, 0.7133, 0.0411, 0.1896, 0.0128, 0.3695,\n",
      "        0.2356, 0.1759, 0.1896, 0.0109, 0.2887, 0.7406, 0.1599, 0.1630, 0.1141,\n",
      "        0.0411, 0.0635, 0.2194, 0.3966, 0.0854, 0.0376, 0.1188, 0.0802, 0.0037,\n",
      "        0.1314, 0.0269, 0.8048, 0.2041, 0.5724], grad_fn=<SigmoidBackward0>)\n",
      "Tensor1:  tensor([107.2772, 183.0022,  84.7644, 112.3937,  57.1350, 159.4660, 146.1630,\n",
      "         96.0208, 148.2096, 108.3005, 134.9066, 101.1373, 120.5802, 121.6035,\n",
      "         97.0441, 134.9066, 166.6292,  87.8343, 149.2329, 142.0697, 107.2772,\n",
      "        112.3937, 110.3471,  80.6711, 113.4171, 128.7667, 154.3495, 190.1653,\n",
      "         86.8110,  92.9509,  94.9975,  85.7877])\n",
      "Tensor2:  tensor(101., requires_grad=True)\n",
      "Tensor1 Normalized:  tensor([0.3769, 0.9462, 0.2077, 0.4154, 0.0000, 0.7692, 0.6692, 0.2923, 0.6846,\n",
      "        0.3846, 0.5846, 0.3308, 0.4769, 0.4846, 0.3000, 0.5846, 0.8231, 0.2308,\n",
      "        0.6923, 0.6385, 0.3769, 0.4154, 0.4000, 0.1769, 0.4231, 0.5385, 0.7308,\n",
      "        1.0000, 0.2231, 0.2692, 0.2846, 0.2154], grad_fn=<DivBackward0>)\n",
      "Tensor2 Normalized:  tensor([0.3297], grad_fn=<DivBackward0>)\n",
      "Result:  tensor([0.4182, 0.0132, 0.7015, 0.3545, 0.9096, 0.0441, 0.0850, 0.5651, 0.0770,\n",
      "        0.4051, 0.1438, 0.4982, 0.2630, 0.2527, 0.5519, 0.1438, 0.0307, 0.6666,\n",
      "        0.0732, 0.1033, 0.4182, 0.3545, 0.3795, 0.7445, 0.3422, 0.1883, 0.0569,\n",
      "        0.0091, 0.6784, 0.6043, 0.5783, 0.6901], grad_fn=<SigmoidBackward0>)\n",
      "Tensor1:  tensor([23.1624, 41.5962, 30.5168, 36.9161, 22.2073, 39.1129, 32.0450, 44.0795,\n",
      "        28.2245, 30.8988, 32.4270, 32.0450, 44.7481, 29.7527, 21.6342, 32.9046,\n",
      "        32.8091, 34.5283, 39.1129, 37.2026, 31.2809, 27.7470, 35.8655, 39.4949,\n",
      "        34.3373, 36.1520, 49.2371, 33.8597, 40.9276, 20.1060, 31.6629, 24.7861])\n",
      "Tensor2:  tensor(26., requires_grad=True)\n",
      "Tensor1 Normalized:  tensor([0.1049, 0.7377, 0.3574, 0.5770, 0.0721, 0.6525, 0.4098, 0.8230, 0.2787,\n",
      "        0.3705, 0.4230, 0.4098, 0.8459, 0.3311, 0.0525, 0.4393, 0.4361, 0.4951,\n",
      "        0.6525, 0.5869, 0.3836, 0.2623, 0.5410, 0.6656, 0.4885, 0.5508, 1.0000,\n",
      "        0.4721, 0.7148, 0.0000, 0.3967, 0.1607], grad_fn=<DivBackward0>)\n",
      "Tensor2 Normalized:  tensor([0.2023], grad_fn=<DivBackward0>)\n",
      "Result:  tensor([0.6642, 0.0230, 0.2525, 0.0677, 0.7133, 0.0411, 0.1896, 0.0128, 0.3695,\n",
      "        0.2356, 0.1759, 0.1896, 0.0109, 0.2887, 0.7406, 0.1599, 0.1630, 0.1141,\n",
      "        0.0411, 0.0635, 0.2194, 0.3966, 0.0854, 0.0376, 0.1188, 0.0802, 0.0037,\n",
      "        0.1314, 0.0269, 0.8048, 0.2041, 0.5724], grad_fn=<SigmoidBackward0>)\n",
      "Tensor1:  tensor([107.2772, 183.0022,  84.7644, 112.3937,  57.1350, 159.4660, 146.1630,\n",
      "         96.0208, 148.2096, 108.3005, 134.9066, 101.1373, 120.5802, 121.6035,\n",
      "         97.0441, 134.9066, 166.6292,  87.8343, 149.2329, 142.0697, 107.2772,\n",
      "        112.3937, 110.3471,  80.6711, 113.4171, 128.7667, 154.3495, 190.1653,\n",
      "         86.8110,  92.9509,  94.9975,  85.7877])\n",
      "Tensor2:  tensor(101., requires_grad=True)\n",
      "Tensor1 Normalized:  tensor([0.3769, 0.9462, 0.2077, 0.4154, 0.0000, 0.7692, 0.6692, 0.2923, 0.6846,\n",
      "        0.3846, 0.5846, 0.3308, 0.4769, 0.4846, 0.3000, 0.5846, 0.8231, 0.2308,\n",
      "        0.6923, 0.6385, 0.3769, 0.4154, 0.4000, 0.1769, 0.4231, 0.5385, 0.7308,\n",
      "        1.0000, 0.2231, 0.2692, 0.2846, 0.2154], grad_fn=<DivBackward0>)\n",
      "Tensor2 Normalized:  tensor([0.3297], grad_fn=<DivBackward0>)\n",
      "Result:  tensor([0.4182, 0.0132, 0.7015, 0.3545, 0.9096, 0.0441, 0.0850, 0.5651, 0.0770,\n",
      "        0.4051, 0.1438, 0.4982, 0.2630, 0.2527, 0.5519, 0.1438, 0.0307, 0.6666,\n",
      "        0.0732, 0.1033, 0.4182, 0.3545, 0.3795, 0.7445, 0.3422, 0.1883, 0.0569,\n",
      "        0.0091, 0.6784, 0.6043, 0.5783, 0.6901], grad_fn=<SigmoidBackward0>)\n",
      "Tensor1:  tensor([23.1624, 41.5962, 30.5168, 36.9161, 22.2073, 39.1129, 32.0450, 44.0795,\n",
      "        28.2245, 30.8988, 32.4270, 32.0450, 44.7481, 29.7527, 21.6342, 32.9046,\n",
      "        32.8091, 34.5283, 39.1129, 37.2026, 31.2809, 27.7470, 35.8655, 39.4949,\n",
      "        34.3373, 36.1520, 49.2371, 33.8597, 40.9276, 20.1060, 31.6629, 24.7861])\n",
      "Tensor2:  tensor(26., requires_grad=True)\n",
      "Tensor1 Normalized:  tensor([0.1049, 0.7377, 0.3574, 0.5770, 0.0721, 0.6525, 0.4098, 0.8230, 0.2787,\n",
      "        0.3705, 0.4230, 0.4098, 0.8459, 0.3311, 0.0525, 0.4393, 0.4361, 0.4951,\n",
      "        0.6525, 0.5869, 0.3836, 0.2623, 0.5410, 0.6656, 0.4885, 0.5508, 1.0000,\n",
      "        0.4721, 0.7148, 0.0000, 0.3967, 0.1607], grad_fn=<DivBackward0>)\n",
      "Tensor2 Normalized:  tensor([0.2023], grad_fn=<DivBackward0>)\n",
      "Result:  tensor([0.6642, 0.0230, 0.2525, 0.0677, 0.7133, 0.0411, 0.1896, 0.0128, 0.3695,\n",
      "        0.2356, 0.1759, 0.1896, 0.0109, 0.2887, 0.7406, 0.1599, 0.1630, 0.1141,\n",
      "        0.0411, 0.0635, 0.2194, 0.3966, 0.0854, 0.0376, 0.1188, 0.0802, 0.0037,\n",
      "        0.1314, 0.0269, 0.8048, 0.2041, 0.5724], grad_fn=<SigmoidBackward0>)\n",
      "Tensor1:  tensor([107.2772, 183.0022,  84.7644, 112.3937,  57.1350, 159.4660, 146.1630,\n",
      "         96.0208, 148.2096, 108.3005, 134.9066, 101.1373, 120.5802, 121.6035,\n",
      "         97.0441, 134.9066, 166.6292,  87.8343, 149.2329, 142.0697, 107.2772,\n",
      "        112.3937, 110.3471,  80.6711, 113.4171, 128.7667, 154.3495, 190.1653,\n",
      "         86.8110,  92.9509,  94.9975,  85.7877])\n",
      "Tensor2:  tensor(101., requires_grad=True)\n",
      "Tensor1 Normalized:  tensor([0.3769, 0.9462, 0.2077, 0.4154, 0.0000, 0.7692, 0.6692, 0.2923, 0.6846,\n",
      "        0.3846, 0.5846, 0.3308, 0.4769, 0.4846, 0.3000, 0.5846, 0.8231, 0.2308,\n",
      "        0.6923, 0.6385, 0.3769, 0.4154, 0.4000, 0.1769, 0.4231, 0.5385, 0.7308,\n",
      "        1.0000, 0.2231, 0.2692, 0.2846, 0.2154], grad_fn=<DivBackward0>)\n",
      "Tensor2 Normalized:  tensor([0.3297], grad_fn=<DivBackward0>)\n",
      "Result:  tensor([0.4182, 0.0132, 0.7015, 0.3545, 0.9096, 0.0441, 0.0850, 0.5651, 0.0770,\n",
      "        0.4051, 0.1438, 0.4982, 0.2630, 0.2527, 0.5519, 0.1438, 0.0307, 0.6666,\n",
      "        0.0732, 0.1033, 0.4182, 0.3545, 0.3795, 0.7445, 0.3422, 0.1883, 0.0569,\n",
      "        0.0091, 0.6784, 0.6043, 0.5783, 0.6901], grad_fn=<SigmoidBackward0>)\n",
      "Tensor1:  tensor([23.1624, 41.5962, 30.5168, 36.9161, 22.2073, 39.1129, 32.0450, 44.0795,\n",
      "        28.2245, 30.8988, 32.4270, 32.0450, 44.7481, 29.7527, 21.6342, 32.9046,\n",
      "        32.8091, 34.5283, 39.1129, 37.2026, 31.2809, 27.7470, 35.8655, 39.4949,\n",
      "        34.3373, 36.1520, 49.2371, 33.8597, 40.9276, 20.1060, 31.6629, 24.7861])\n",
      "Tensor2:  tensor(26., requires_grad=True)\n",
      "Tensor1 Normalized:  tensor([0.1049, 0.7377, 0.3574, 0.5770, 0.0721, 0.6525, 0.4098, 0.8230, 0.2787,\n",
      "        0.3705, 0.4230, 0.4098, 0.8459, 0.3311, 0.0525, 0.4393, 0.4361, 0.4951,\n",
      "        0.6525, 0.5869, 0.3836, 0.2623, 0.5410, 0.6656, 0.4885, 0.5508, 1.0000,\n",
      "        0.4721, 0.7148, 0.0000, 0.3967, 0.1607], grad_fn=<DivBackward0>)\n",
      "Tensor2 Normalized:  tensor([0.2023], grad_fn=<DivBackward0>)\n",
      "Result:  tensor([0.6642, 0.0230, 0.2525, 0.0677, 0.7133, 0.0411, 0.1896, 0.0128, 0.3695,\n",
      "        0.2356, 0.1759, 0.1896, 0.0109, 0.2887, 0.7406, 0.1599, 0.1630, 0.1141,\n",
      "        0.0411, 0.0635, 0.2194, 0.3966, 0.0854, 0.0376, 0.1188, 0.0802, 0.0037,\n",
      "        0.1314, 0.0269, 0.8048, 0.2041, 0.5724], grad_fn=<SigmoidBackward0>)\n",
      "Tensor1:  tensor([107.2772, 183.0022,  84.7644, 112.3937,  57.1350, 159.4660, 146.1630,\n",
      "         96.0208, 148.2096, 108.3005, 134.9066, 101.1373, 120.5802, 121.6035,\n",
      "         97.0441, 134.9066, 166.6292,  87.8343, 149.2329, 142.0697, 107.2772,\n",
      "        112.3937, 110.3471,  80.6711, 113.4171, 128.7667, 154.3495, 190.1653,\n",
      "         86.8110,  92.9509,  94.9975,  85.7877])\n",
      "Tensor2:  tensor(101., requires_grad=True)\n",
      "Tensor1 Normalized:  tensor([0.3769, 0.9462, 0.2077, 0.4154, 0.0000, 0.7692, 0.6692, 0.2923, 0.6846,\n",
      "        0.3846, 0.5846, 0.3308, 0.4769, 0.4846, 0.3000, 0.5846, 0.8231, 0.2308,\n",
      "        0.6923, 0.6385, 0.3769, 0.4154, 0.4000, 0.1769, 0.4231, 0.5385, 0.7308,\n",
      "        1.0000, 0.2231, 0.2692, 0.2846, 0.2154], grad_fn=<DivBackward0>)\n",
      "Tensor2 Normalized:  tensor([0.3297], grad_fn=<DivBackward0>)\n",
      "Result:  tensor([0.4182, 0.0132, 0.7015, 0.3545, 0.9096, 0.0441, 0.0850, 0.5651, 0.0770,\n",
      "        0.4051, 0.1438, 0.4982, 0.2630, 0.2527, 0.5519, 0.1438, 0.0307, 0.6666,\n",
      "        0.0732, 0.1033, 0.4182, 0.3545, 0.3795, 0.7445, 0.3422, 0.1883, 0.0569,\n",
      "        0.0091, 0.6784, 0.6043, 0.5783, 0.6901], grad_fn=<SigmoidBackward0>)\n",
      "Tensor1:  tensor([23.1624, 41.5962, 30.5168, 36.9161, 22.2073, 39.1129, 32.0450, 44.0795,\n",
      "        28.2245, 30.8988, 32.4270, 32.0450, 44.7481, 29.7527, 21.6342, 32.9046,\n",
      "        32.8091, 34.5283, 39.1129, 37.2026, 31.2809, 27.7470, 35.8655, 39.4949,\n",
      "        34.3373, 36.1520, 49.2371, 33.8597, 40.9276, 20.1060, 31.6629, 24.7861])\n",
      "Tensor2:  tensor(26., requires_grad=True)\n",
      "Tensor1 Normalized:  tensor([0.1049, 0.7377, 0.3574, 0.5770, 0.0721, 0.6525, 0.4098, 0.8230, 0.2787,\n",
      "        0.3705, 0.4230, 0.4098, 0.8459, 0.3311, 0.0525, 0.4393, 0.4361, 0.4951,\n",
      "        0.6525, 0.5869, 0.3836, 0.2623, 0.5410, 0.6656, 0.4885, 0.5508, 1.0000,\n",
      "        0.4721, 0.7148, 0.0000, 0.3967, 0.1607], grad_fn=<DivBackward0>)\n",
      "Tensor2 Normalized:  tensor([0.2023], grad_fn=<DivBackward0>)\n",
      "Result:  tensor([0.6642, 0.0230, 0.2525, 0.0677, 0.7133, 0.0411, 0.1896, 0.0128, 0.3695,\n",
      "        0.2356, 0.1759, 0.1896, 0.0109, 0.2887, 0.7406, 0.1599, 0.1630, 0.1141,\n",
      "        0.0411, 0.0635, 0.2194, 0.3966, 0.0854, 0.0376, 0.1188, 0.0802, 0.0037,\n",
      "        0.1314, 0.0269, 0.8048, 0.2041, 0.5724], grad_fn=<SigmoidBackward0>)\n",
      "Tensor1:  tensor([107.2772, 183.0022,  84.7644, 112.3937,  57.1350, 159.4660, 146.1630,\n",
      "         96.0208, 148.2096, 108.3005, 134.9066, 101.1373, 120.5802, 121.6035,\n",
      "         97.0441, 134.9066, 166.6292,  87.8343, 149.2329, 142.0697, 107.2772,\n",
      "        112.3937, 110.3471,  80.6711, 113.4171, 128.7667, 154.3495, 190.1653,\n",
      "         86.8110,  92.9509,  94.9975,  85.7877])\n",
      "Tensor2:  tensor(101., requires_grad=True)\n",
      "Tensor1 Normalized:  tensor([0.3769, 0.9462, 0.2077, 0.4154, 0.0000, 0.7692, 0.6692, 0.2923, 0.6846,\n",
      "        0.3846, 0.5846, 0.3308, 0.4769, 0.4846, 0.3000, 0.5846, 0.8231, 0.2308,\n",
      "        0.6923, 0.6385, 0.3769, 0.4154, 0.4000, 0.1769, 0.4231, 0.5385, 0.7308,\n",
      "        1.0000, 0.2231, 0.2692, 0.2846, 0.2154], grad_fn=<DivBackward0>)\n",
      "Tensor2 Normalized:  tensor([0.3297], grad_fn=<DivBackward0>)\n",
      "Result:  tensor([0.4182, 0.0132, 0.7015, 0.3545, 0.9096, 0.0441, 0.0850, 0.5651, 0.0770,\n",
      "        0.4051, 0.1438, 0.4982, 0.2630, 0.2527, 0.5519, 0.1438, 0.0307, 0.6666,\n",
      "        0.0732, 0.1033, 0.4182, 0.3545, 0.3795, 0.7445, 0.3422, 0.1883, 0.0569,\n",
      "        0.0091, 0.6784, 0.6043, 0.5783, 0.6901], grad_fn=<SigmoidBackward0>)\n",
      "Tensor1:  tensor([23.1624, 41.5962, 30.5168, 36.9161, 22.2073, 39.1129, 32.0450, 44.0795,\n",
      "        28.2245, 30.8988, 32.4270, 32.0450, 44.7481, 29.7527, 21.6342, 32.9046,\n",
      "        32.8091, 34.5283, 39.1129, 37.2026, 31.2809, 27.7470, 35.8655, 39.4949,\n",
      "        34.3373, 36.1520, 49.2371, 33.8597, 40.9276, 20.1060, 31.6629, 24.7861])\n",
      "Tensor2:  tensor(26., requires_grad=True)\n",
      "Tensor1 Normalized:  tensor([0.1049, 0.7377, 0.3574, 0.5770, 0.0721, 0.6525, 0.4098, 0.8230, 0.2787,\n",
      "        0.3705, 0.4230, 0.4098, 0.8459, 0.3311, 0.0525, 0.4393, 0.4361, 0.4951,\n",
      "        0.6525, 0.5869, 0.3836, 0.2623, 0.5410, 0.6656, 0.4885, 0.5508, 1.0000,\n",
      "        0.4721, 0.7148, 0.0000, 0.3967, 0.1607], grad_fn=<DivBackward0>)\n",
      "Tensor2 Normalized:  tensor([0.2023], grad_fn=<DivBackward0>)\n",
      "Result:  tensor([0.6642, 0.0230, 0.2525, 0.0677, 0.7133, 0.0411, 0.1896, 0.0128, 0.3695,\n",
      "        0.2356, 0.1759, 0.1896, 0.0109, 0.2887, 0.7406, 0.1599, 0.1630, 0.1141,\n",
      "        0.0411, 0.0635, 0.2194, 0.3966, 0.0854, 0.0376, 0.1188, 0.0802, 0.0037,\n",
      "        0.1314, 0.0269, 0.8048, 0.2041, 0.5724], grad_fn=<SigmoidBackward0>)\n",
      "Tensor1:  tensor([107.2772, 183.0022,  84.7644, 112.3937,  57.1350, 159.4660, 146.1630,\n",
      "         96.0208, 148.2096, 108.3005, 134.9066, 101.1373, 120.5802, 121.6035,\n",
      "         97.0441, 134.9066, 166.6292,  87.8343, 149.2329, 142.0697, 107.2772,\n",
      "        112.3937, 110.3471,  80.6711, 113.4171, 128.7667, 154.3495, 190.1653,\n",
      "         86.8110,  92.9509,  94.9975,  85.7877])\n",
      "Tensor2:  tensor(101., requires_grad=True)\n",
      "Tensor1 Normalized:  tensor([0.3769, 0.9462, 0.2077, 0.4154, 0.0000, 0.7692, 0.6692, 0.2923, 0.6846,\n",
      "        0.3846, 0.5846, 0.3308, 0.4769, 0.4846, 0.3000, 0.5846, 0.8231, 0.2308,\n",
      "        0.6923, 0.6385, 0.3769, 0.4154, 0.4000, 0.1769, 0.4231, 0.5385, 0.7308,\n",
      "        1.0000, 0.2231, 0.2692, 0.2846, 0.2154], grad_fn=<DivBackward0>)\n",
      "Tensor2 Normalized:  tensor([0.3297], grad_fn=<DivBackward0>)\n",
      "Result:  tensor([0.4182, 0.0132, 0.7015, 0.3545, 0.9096, 0.0441, 0.0850, 0.5651, 0.0770,\n",
      "        0.4051, 0.1438, 0.4982, 0.2630, 0.2527, 0.5519, 0.1438, 0.0307, 0.6666,\n",
      "        0.0732, 0.1033, 0.4182, 0.3545, 0.3795, 0.7445, 0.3422, 0.1883, 0.0569,\n",
      "        0.0091, 0.6784, 0.6043, 0.5783, 0.6901], grad_fn=<SigmoidBackward0>)\n",
      "Tensor1:  tensor([23.1624, 41.5962, 30.5168, 36.9161, 22.2073, 39.1129, 32.0450, 44.0795,\n",
      "        28.2245, 30.8988, 32.4270, 32.0450, 44.7481, 29.7527, 21.6342, 32.9046,\n",
      "        32.8091, 34.5283, 39.1129, 37.2026, 31.2809, 27.7470, 35.8655, 39.4949,\n",
      "        34.3373, 36.1520, 49.2371, 33.8597, 40.9276, 20.1060, 31.6629, 24.7861])\n",
      "Tensor2:  tensor(26., requires_grad=True)\n",
      "Tensor1 Normalized:  tensor([0.1049, 0.7377, 0.3574, 0.5770, 0.0721, 0.6525, 0.4098, 0.8230, 0.2787,\n",
      "        0.3705, 0.4230, 0.4098, 0.8459, 0.3311, 0.0525, 0.4393, 0.4361, 0.4951,\n",
      "        0.6525, 0.5869, 0.3836, 0.2623, 0.5410, 0.6656, 0.4885, 0.5508, 1.0000,\n",
      "        0.4721, 0.7148, 0.0000, 0.3967, 0.1607], grad_fn=<DivBackward0>)\n",
      "Tensor2 Normalized:  tensor([0.2023], grad_fn=<DivBackward0>)\n",
      "Result:  tensor([0.6642, 0.0230, 0.2525, 0.0677, 0.7133, 0.0411, 0.1896, 0.0128, 0.3695,\n",
      "        0.2356, 0.1759, 0.1896, 0.0109, 0.2887, 0.7406, 0.1599, 0.1630, 0.1141,\n",
      "        0.0411, 0.0635, 0.2194, 0.3966, 0.0854, 0.0376, 0.1188, 0.0802, 0.0037,\n",
      "        0.1314, 0.0269, 0.8048, 0.2041, 0.5724], grad_fn=<SigmoidBackward0>)\n",
      "Tensor1:  tensor([107.2772, 183.0022,  84.7644, 112.3937,  57.1350, 159.4660, 146.1630,\n",
      "         96.0208, 148.2096, 108.3005, 134.9066, 101.1373, 120.5802, 121.6035,\n",
      "         97.0441, 134.9066, 166.6292,  87.8343, 149.2329, 142.0697, 107.2772,\n",
      "        112.3937, 110.3471,  80.6711, 113.4171, 128.7667, 154.3495, 190.1653,\n",
      "         86.8110,  92.9509,  94.9975,  85.7877])\n",
      "Tensor2:  tensor(101., requires_grad=True)\n",
      "Tensor1 Normalized:  tensor([0.3769, 0.9462, 0.2077, 0.4154, 0.0000, 0.7692, 0.6692, 0.2923, 0.6846,\n",
      "        0.3846, 0.5846, 0.3308, 0.4769, 0.4846, 0.3000, 0.5846, 0.8231, 0.2308,\n",
      "        0.6923, 0.6385, 0.3769, 0.4154, 0.4000, 0.1769, 0.4231, 0.5385, 0.7308,\n",
      "        1.0000, 0.2231, 0.2692, 0.2846, 0.2154], grad_fn=<DivBackward0>)\n",
      "Tensor2 Normalized:  tensor([0.3297], grad_fn=<DivBackward0>)\n",
      "Result:  tensor([0.4182, 0.0132, 0.7015, 0.3545, 0.9096, 0.0441, 0.0850, 0.5651, 0.0770,\n",
      "        0.4051, 0.1438, 0.4982, 0.2630, 0.2527, 0.5519, 0.1438, 0.0307, 0.6666,\n",
      "        0.0732, 0.1033, 0.4182, 0.3545, 0.3795, 0.7445, 0.3422, 0.1883, 0.0569,\n",
      "        0.0091, 0.6784, 0.6043, 0.5783, 0.6901], grad_fn=<SigmoidBackward0>)\n",
      "Tensor1:  tensor([27.9940, 27.5971, 33.9476, 35.3765, 29.5022, 27.6765, 31.8837, 30.0579,\n",
      "        24.5806, 35.4559, 33.3126, 39.9806, 24.5806, 42.2827, 35.8528, 42.5208,\n",
      "        34.6621, 27.9146, 36.2497, 34.2651, 28.7084, 27.1208, 28.3115, 30.4548,\n",
      "        59.1910, 29.4229, 22.4373, 26.7239, 33.9476, 23.7868, 42.5208, 28.5497,\n",
      "        37.5198, 33.1538, 33.1538, 30.6930, 27.5177, 34.9796, 30.4548])\n",
      "Tensor2:  tensor(26., requires_grad=True)\n",
      "Tensor1 Normalized:  tensor([0.1512, 0.1404, 0.3132, 0.3521, 0.1922, 0.1425, 0.2570, 0.2073, 0.0583,\n",
      "        0.3542, 0.2959, 0.4773, 0.0583, 0.5400, 0.3650, 0.5464, 0.3326, 0.1490,\n",
      "        0.3758, 0.3218, 0.1706, 0.1274, 0.1598, 0.2181, 1.0000, 0.1901, 0.0000,\n",
      "        0.1166, 0.3132, 0.0367, 0.5464, 0.1663, 0.4104, 0.2916, 0.2916, 0.2246,\n",
      "        0.1382, 0.3413, 0.2181])\n",
      "Tensor2 Normalized:  tensor([0.0969])\n",
      "Result:  tensor([0.4062, 0.4245, 0.1804, 0.1436, 0.3392, 0.4208, 0.2459, 0.3159, 0.5672,\n",
      "        0.1417, 0.1990, 0.0652, 0.5672, 0.0431, 0.1328, 0.0412, 0.1611, 0.4098,\n",
      "        0.1243, 0.1716, 0.3738, 0.4468, 0.3917, 0.2998, 0.0018, 0.3426, 0.6634,\n",
      "        0.4656, 0.1804, 0.6038, 0.0412, 0.3809, 0.1003, 0.2038, 0.2038, 0.2903,\n",
      "        0.4282, 0.1531, 0.2998])\n",
      "Tensor1:  tensor([ 88.4271, 132.1301,  92.0690, 131.2197,  75.6804, 122.1149, 170.3703,\n",
      "        157.6236,  89.3376, 100.2633, 113.9205, 144.8769, 184.0275, 114.8310,\n",
      "        101.1738, 147.6083, 118.4729, 154.8922, 160.3550, 109.3681, 133.9511,\n",
      "        130.3092,  95.7109, 142.1454, 124.8463, 122.1149,  94.8005,  80.2328,\n",
      "         74.7699, 121.2044, 138.5035,  82.0537, 185.8485, 179.4751, 123.9358,\n",
      "         84.7852,  95.7109,  98.4424, 147.6083])\n",
      "Tensor2:  tensor(101., requires_grad=True)\n",
      "Tensor1 Normalized:  tensor([0.1230, 0.5164, 0.1557, 0.5082, 0.0082, 0.4262, 0.8607, 0.7459, 0.1311,\n",
      "        0.2295, 0.3525, 0.6311, 0.9836, 0.3607, 0.2377, 0.6557, 0.3934, 0.7213,\n",
      "        0.7705, 0.3115, 0.5328, 0.5000, 0.1885, 0.6066, 0.4508, 0.4262, 0.1803,\n",
      "        0.0492, 0.0000, 0.4180, 0.5738, 0.0656, 1.0000, 0.9426, 0.4426, 0.0902,\n",
      "        0.1885, 0.2131, 0.6557])\n",
      "Tensor2 Normalized:  tensor([0.2361])\n",
      "Result:  tensor([0.6883, 0.1233, 0.6371, 0.1296, 0.8314, 0.2091, 0.0125, 0.0274, 0.6759,\n",
      "        0.5116, 0.3070, 0.0592, 0.0053, 0.2949, 0.4973, 0.0503, 0.2495, 0.0324,\n",
      "        0.0232, 0.3711, 0.1114, 0.1362, 0.5826, 0.0696, 0.1820, 0.2091, 0.5964,\n",
      "        0.7873, 0.8393, 0.2187, 0.0860, 0.7674, 0.0047, 0.0071, 0.1907, 0.7353,\n",
      "        0.5826, 0.5402, 0.0503])\n",
      "Rule: ∀ ['person']. (((y == diabetes) -> Diabetic(person))), Outcome: 0.8210468888282776\n",
      "Rule: ∀ ['person']. (((y == healthy) -> ~(Diabetic(person)))), Outcome: 0.8166279792785645\n",
      "Rule: ∀ ['person']. ((((person[BMI] > 29) & (person[Glucose] > 125)) -> Diabetic(person))), Outcome: 0.6745266914367676\n",
      "Rule: ∀ ['person']. ((((person[BMI] < 26) & (person[Glucose] < 101)) -> ~(Diabetic(person)))), Outcome: 0.8779618740081787\n",
      "Epoch 1/1, Train Loss: 0.21591413021087646, Validation Loss: 0.2609291076660156\n",
      "\n",
      "Tensor1:  tensor([30.0579, 33.9476, 28.3115, 33.9476, 27.1208, 37.5198, 39.9806, 24.5806,\n",
      "        59.1910, 27.9940, 36.2497, 35.4559, 28.7084, 29.5022, 35.8528, 27.6765,\n",
      "        33.1538, 34.6621, 27.5971, 35.3765, 42.2827, 28.5497, 42.5208, 27.9146,\n",
      "        30.4548, 33.1538, 34.2651, 27.5177, 29.4229, 33.3126, 30.4548, 22.4373,\n",
      "        26.7239, 42.5208, 23.7868, 30.6930, 34.9796, 24.5806, 31.8837])\n",
      "Tensor2:  tensor(26., requires_grad=True)\n",
      "Tensor1 Normalized:  tensor([0.2073, 0.3132, 0.1598, 0.3132, 0.1274, 0.4104, 0.4773, 0.0583, 1.0000,\n",
      "        0.1512, 0.3758, 0.3542, 0.1706, 0.1922, 0.3650, 0.1425, 0.2916, 0.3326,\n",
      "        0.1404, 0.3521, 0.5400, 0.1663, 0.5464, 0.1490, 0.2181, 0.2916, 0.3218,\n",
      "        0.1382, 0.1901, 0.2959, 0.2181, 0.0000, 0.1166, 0.5464, 0.0367, 0.2246,\n",
      "        0.3413, 0.0583, 0.2570])\n",
      "Tensor2 Normalized:  tensor([0.0969])\n",
      "Result:  tensor([0.3159, 0.1804, 0.3917, 0.1804, 0.4468, 0.1003, 0.0652, 0.5672, 0.0018,\n",
      "        0.4062, 0.1243, 0.1417, 0.3738, 0.3392, 0.1328, 0.4208, 0.2038, 0.1611,\n",
      "        0.4245, 0.1436, 0.0431, 0.3809, 0.0412, 0.4098, 0.2998, 0.2038, 0.1716,\n",
      "        0.4282, 0.3426, 0.1990, 0.2998, 0.6634, 0.4656, 0.0412, 0.6038, 0.2903,\n",
      "        0.1531, 0.5672, 0.2459])\n",
      "Tensor1:  tensor([157.6236,  92.0690,  95.7109,  74.7699, 130.3092, 185.8485, 144.8769,\n",
      "         89.3376, 124.8463,  88.4271, 160.3550, 100.2633, 133.9511,  75.6804,\n",
      "        101.1738, 122.1149, 123.9358, 118.4729, 132.1301, 131.2197, 114.8310,\n",
      "         82.0537, 147.6083, 154.8922, 147.6083, 179.4751, 109.3681,  95.7109,\n",
      "        122.1149, 113.9205, 142.1454,  94.8005,  80.2328, 138.5035, 121.2044,\n",
      "         84.7852,  98.4424, 184.0275, 170.3703])\n",
      "Tensor2:  tensor(101., requires_grad=True)\n",
      "Tensor1 Normalized:  tensor([0.7459, 0.1557, 0.1885, 0.0000, 0.5000, 1.0000, 0.6311, 0.1311, 0.4508,\n",
      "        0.1230, 0.7705, 0.2295, 0.5328, 0.0082, 0.2377, 0.4262, 0.4426, 0.3934,\n",
      "        0.5164, 0.5082, 0.3607, 0.0656, 0.6557, 0.7213, 0.6557, 0.9426, 0.3115,\n",
      "        0.1885, 0.4262, 0.3525, 0.6066, 0.1803, 0.0492, 0.5738, 0.4180, 0.0902,\n",
      "        0.2131, 0.9836, 0.8607])\n",
      "Tensor2 Normalized:  tensor([0.2361])\n",
      "Result:  tensor([0.0274, 0.6371, 0.5826, 0.8393, 0.1362, 0.0047, 0.0592, 0.6759, 0.1820,\n",
      "        0.6883, 0.0232, 0.5116, 0.1114, 0.8314, 0.4973, 0.2091, 0.1907, 0.2495,\n",
      "        0.1233, 0.1296, 0.2949, 0.7674, 0.0503, 0.0324, 0.0503, 0.0071, 0.3711,\n",
      "        0.5826, 0.2091, 0.3070, 0.0696, 0.5964, 0.7873, 0.0860, 0.2187, 0.7353,\n",
      "        0.5402, 0.0053, 0.0125])\n"
     ]
    }
   ],
   "source": [
    "if fine_tune:\n",
    "    kb.optimize(num_epochs=1, log_steps=10, lr=0.000001, early_stopping=True, patience=5)\n",
    "else:\n",
    "    kb.optimize(num_epochs=150, log_steps=10, lr=0.00001, early_stopping=False, patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([7.0000], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([7.0000], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([7.0000], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([7.0000], requires_grad=True)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[op.k for op in kb.converter.visitor.comparision_operators]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positives: 95, False Positives: 12, False Negatives: 25, True Negatives: 213, Total: 345\n",
      "\n",
      "A (Accuracy): 0.8928\n",
      "P (Precision): 0.8879\n",
      "R (Recall): 0.7917\n",
      "F1 (F1 Score): 0.8370\n",
      "BA (Balanced Accuracy): 0.8692\n",
      "MCC (Matthews Correlation Coefficient): 0.7602\n",
      "TNR (True Negative Rate): 0.9467\n",
      "FPR (False Positive Rate): 0.0533\n",
      "FNR (False Negative Rate): 0.2083\n",
      "TPR (True Positive Rate): 0.7917\n"
     ]
    }
   ],
   "source": [
    "compute_metrics(kb.predicates[\"Diabetic\"], kb.loaders[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positives: 80, False Positives: 35, False Negatives: 54, True Negatives: 215, Total: 384\n",
      "\n",
      "A (Accuracy): 0.7682\n",
      "P (Precision): 0.6957\n",
      "R (Recall): 0.5970\n",
      "F1 (F1 Score): 0.6426\n",
      "BA (Balanced Accuracy): 0.7285\n",
      "MCC (Matthews Correlation Coefficient): 0.4756\n",
      "TNR (True Negative Rate): 0.8600\n",
      "FPR (False Positive Rate): 0.1400\n",
      "FNR (False Negative Rate): 0.4030\n",
      "TPR (True Positive Rate): 0.5970\n"
     ]
    }
   ],
   "source": [
    "compute_metrics(kb.predicates[\"Diabetic\"], kb.test_loaders[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
